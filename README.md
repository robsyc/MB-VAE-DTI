# Multi-branch Neural Networks for Drug-target Interaction Prediction and Target-conditioned de novo Drug Design (MB-VAE-DTI)

A machine-learning framework for the dyadic drug-target interaction (DTI) prediction problem that combines multi-branch variational autoencoders with discrete diffusion processes. Our architecture uniquely integrates multiple drug/target representations and modalities, pre-trained foundation models, and target-conditioned discrete diffusion-based molecule generation in a unified framework.

**Key features of this project:**
- Multiple drug representations: Morgan fingerprints, graph, image and text (SMILES)
- Multiple protein representations: ESPF fingerprints, amino acid and DNA sequences
- Variational encoders and discrete-diffusion decoder for de novo drug design
- Inspection of latent spaces & exploration of generative capabilities
- Comprehensive evaluation on standard DTI datasets through [tdc](https://tdcommons.ai/) (DAVIS, KIBA, BindingDB and Metz) and a new aggregated dataset of Â±300k interactions & pre-computed embeddings.

**Prior work which this project builds upon:**
- [`DiGress`](https://github.com/cvignac/DiGress) by [Vignac et al.](https://arxiv.org/abs/2209.14734) and [`DiffMS`](https://github.com/coleygroup/DiffMS) by [Coley et al.](https://arxiv.org/abs/2409.10000) which inspired the diffusion-based drug-decoding.
- [`RDKit`](https://www.rdkit.org/) with Morgan fingerprints for generating drug fingerprints.
- [`MMELON`](https://github.com/BiomedSciAI/biomed-multi-view) model by [Suryanarayanan et al.](https://arxiv.org/abs/2410.19704) for generating drug representation embeddings (graph, image and text).
- [`ESPF`](https://github.com/kexinhuang12345/ESPF) by [Huang et al.](https://static1.squarespace.com/static/58f7aae1e6f2e1a0f9a56616/t/5e370e2d12092f15876d5753/1580666413389/paper.pdf) for generating protein fingerprints.
- [`ESM-C 600M`](https://github.com/evolutionaryscale/esm) by the [ESM Team](https://evolutionaryscale.ai/blog/esm-cambrian) for generating protein language model embeddings.
- [`nucleotide-transformer 500M_multi_species_v2`](https://github.com/instadeepai/nucleotide-transformer) by [Dalla-Torre et al.](https://www.biorxiv.org/content/10.1101/2023.01.11.523679v2) for the generation of DNA sequence embeddings.

## Repository Structure

```
MB-VAE-DTI/
â”œâ”€â”€ mb_vae_dti/                 # Main Python package
â”‚   â”œâ”€â”€ loading/                # Loading and preprocessing datasets
â”‚   â”‚   â”œâ”€â”€ datasets.py         # Loading, merging, filtering and saving initial DTI datasets
â”‚   â”‚   â”œâ”€â”€ annotation.py       # Addition of DNA sequences, InChI keys, etc.
â”‚   â”‚   â””â”€â”€ visualization.py    # Plotting metrics for loaded data
|   | 
â”‚   â”œâ”€â”€ processing/             # Embedding & h5torch file creation
â”‚   â”‚   â”œâ”€â”€ embedding.py        # Embedding generation
â”‚   â”‚   â”œâ”€â”€ h5factory.py        # h5torch file creation
â”‚   â”‚   â””â”€â”€ split.py            # DTI dataset splitting
|   |
â”‚   â”œâ”€â”€ training/               # Model training (in progress)
â”‚   â”‚   â”œâ”€â”€ configs/            # Configuration files (incl. gridsearch & ensemble)
â”‚   â”‚   â”œâ”€â”€ datasets/           # PyTorch Lightning DataModules for DTI & pretraining
â”‚   â”‚   â”œâ”€â”€ models/             # Model architectures & components
â”‚   â”‚   â”œâ”€â”€ metrics/            # Pyl metrics for DTI accuracy, and molecular reconstruction
|   |   â”œâ”€â”€ modules/            # Pyl modules for DTI models
|   |   â”œâ”€â”€ diffusion/          # Diffusion utilities (in progress)
â”‚   â”‚   â”œâ”€â”€ utils/              # Training & testing utilities
â”‚   â”‚   â””â”€â”€ run.py & test.py    # Main training & testing scripts
|   |
â”‚   â””â”€â”€ validating/             # Validation and analysis (in progress)
â”‚       â”œâ”€â”€ ...
â”‚       â””â”€â”€ ...
|
â”œâ”€â”€ external/                   # External dependencies (each has it's own requirements.txt and script.py)
â”‚   â”œâ”€â”€ rdMorganFP/             # Drug fingerprinting utilities
â”‚   â”œâ”€â”€ biomed-multi-view/      # Biomed-multi-view embedding models
â”‚   â”œâ”€â”€ ESPF/                   # Protein fingerprinting utilities
â”‚   â”œâ”€â”€ ESM/                    # Protein language model (ESM-C 6B)
â”‚   â”œâ”€â”€ nucleotide-transformer/ # DNA sequence transformer (500M_multi_species_v2)
|   â”œâ”€â”€ temp/                   # Directory for storing HDF5 files
â”‚   â””â”€â”€ run_embeddings.sh       # Shell script to run embedding generation
|
â”œâ”€â”€ data/                       # Data directory (gitignored)
â”‚   â”œâ”€â”€ source/                 # Original datasets, populated by loading notebook & tdc
â”‚   â”œâ”€â”€ processed/              # Processed datasets & embeddings
â”‚   â”œâ”€â”€ input/                  # Input datasets (h5torch)
â”‚   â”œâ”€â”€ images/                 # Plots and visualizations
â”‚   â””â”€â”€ results/                # Model outputs and checkpoints
|
â”œâ”€â”€ notebooks/                  # Jupyter notebooks for reproducing experiments
â”‚   â”œâ”€â”€ loading.ipynb           # Data loading, pre-processing and exploration
â”‚   â”œâ”€â”€ processing.ipynb        # Embedding generation and h5torch file creation
â”‚   â”œâ”€â”€ training.ipynb          # Gridsearch analysis & metrics (in progress)
â”‚   â””â”€â”€ validating.ipynb        # Inspection of generative quirks (in progress)
|
â”œâ”€â”€ scripts/                    # Shell scripts for running jobs
â”‚   â”œâ”€â”€ embedding/
â”‚   â”œâ”€â”€ training/
â”‚   â””â”€â”€ molecular_statistics.py # Molecular properties, marginal distributions, ...
|
â”œâ”€â”€ environment.yml             # Minimal conda setup (Python + RDKit + PyTorch CUDA)
â”œâ”€â”€ pyproject.toml              # All other dependencies (DiffMS + MB-VAE-DTI)
â””â”€â”€ README.md                   # This file :)
```

## Installation

### Prerequisites

- [Conda](https://docs.conda.io/en/latest/miniconda.html) package manager
- CUDA-compatible GPU (recommended)

### Setup

```bash
git clone https://github.com/robsyc/MB-VAE-DTI.git
cd MB-VAE-DTI
conda env create -f environment.yml
conda activate mb-vae-dti
```

## Quick Start

**Download the complete data folder** including all datasets and pre-trained models:
   - Link: TBA (coming soon)
   - This provides everything needed to immediately start experimenting with the models
   - Alternatively, you can consult the notebooks to generate the data & run all experiments from scratch
  
  ```bash
  # simplest baseline on random split of DAVIS
  python mb_vae_dti/training/run.py --model baseline --phase finetune --dataset DAVIS --split rand

  # full model on cold split of KIBA
  python mb_vae_dti/training/run.py --model full --phase finetune --dataset KIBA --split cold
  ```

  See `training/run.py` and `training/configs/` for more examples and details.

**Note:** This project is currently in development (training/validation components in progress). There currently are still some `archive` folders spread throughout the repository, which contain old code to be refactored.

## Current Progress

- âœ… Data loading and preprocessing
- âœ… Embedding generation and processing
- âœ… h5torch file creation and dataset splitting
- âœ… Setting up model architectures
- ðŸ”„ Model pre-training w/ contrastive, complexity, (reconstruction) loss
  - Contrastive loss: SimCLR with InfoNCE (1 positive pair and many negatives weighted w/ Tanimoto similarity)
  - Complexity loss: KL divergence between the encoder's output and a standard normal distribution
  - Reconstruction loss: MSE between the diffusion decoder's output and the input (only for the drug branch)
- ðŸ”„ Training baseline model (MLP on FPs & dot-product) and full model (incl. DTI accuracy loss)
- ðŸ”„ Model validation and analysis

## Citation

If you use this code in your research, please cite:

```
@article{mbvae_dti,
   title={Multi-branch VAE for Drug-target Interaction Prediction and Target-conditioned de novo Drug Design},
   author={Claeys, Robbe},
   year={2025},
   url={https://...}
}
```

## Acknowledgments

This work is part of a master thesis project at [UGent](https://www.ugent.be/en) under the supervision of [Prof. Willem Waegeman](https://www.ugent.be/dass/en/research/waegeman), [Gaetan De Waele](https://github.com/gdewael) and [Natan TournÃ©](https://willemwaegeman.github.io/bioml/members/natan-tourne.html) at the [BioML lab](https://willemwaegeman.github.io/bioml/).