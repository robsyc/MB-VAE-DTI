#!/bin/bash

# Basic parameters
#PBS -N baseline_davis_cold         ## Job name
#PBS -l nodes=1:ppn=8:gpus=1    ## nodes, processors per node (ppn=all to get a full node), GPUs (H100 with 32gb)
#PBS -l walltime=00:15:00       ## Max time your job will run (no more than 72:00:00)
#PBS -l mem=16gb                ## If not used, memory will be available proportional to the max amount
#PBS -m abe                     ## Email notifications (abe=aborted, begin and end)

# Load the necessary modules
ml load PyTorch/2.1.2-foss-2023a-CUDA-12.1.1
ml load PyTorch-Lightning/2.2.1-foss-2023a-CUDA-12.1.1
ml load Hydra/1.3.2-foss-2023a-with-plugins
ml load wandb/0.16.1-GCC-12.3.0
ml load PyTorch-Geometric/2.5.0-foss-2023a-PyTorch-2.1.2-CUDA-12.1.1
ml load lifelines/0.28.0-gfbf-2023a
ml load RDKit/2024.03.3-foss-2023a
pip install torcheval h5torch pytdc

# Change working directory to the location where the job was submmitted
cd /data/gent/454/vsc45450/thesis/MB-VAE-DTI

python3 mb_vae_dti/training/run.py --model baseline --phase finetune --dataset DAVIS --split cold