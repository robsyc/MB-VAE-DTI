model:
  checkpoint_path: "data/results/multi_hybrid/pretrain/rand/multi_hybrid_pretrain_rand/checkpoints/best_model.pt"

training:
  learning_rate: 0.0001

data:
  batch_size: 32
  
logging:
  experiment_name: "multi_hybrid_KIBA_rand"
  save_dir: "data/results/multi_hybrid/KIBA/rand"

gridsearch:
  training.learning_rate: [0.0001, 0.0005, 0.001]
  data.batch_size: [16, 32, 64]