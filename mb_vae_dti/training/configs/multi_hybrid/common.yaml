# Multi-Hybrid Model Common Configuration
#   Combines multi-modal inputs with multi-output predictions
#   Supports individual branch pretraining with contrastive learning
#   These configurations are shared across all training phases

model:
  encoder_kwargs:
    dropout: 0.1
    activation: "gelu"

  aggregator_kwargs:
    dropout: 0.1
    activation: "gelu"

  fusion_kwargs:
    dropout: 0.1
    output_dim: 256

  dti_head_kwargs:
    hidden_dim: 128
    dropout: 0.1
  
  # Contrastive learning parameters
  infonce_head_kwargs:
    output_dim: 128
    temperature: 0.07
  contrastive_weight: 1.0
  temperature: 0.07
    
training:
  scheduler: "one_cycle"  # "const", "step", "one_cycle", or "cosine"
    
data:
  h5_path: "data/input/dti.h5torch"
  drug_features: ["EMB-BiomedGraph", "EMB-BiomedImg", "EMB-BiomedText"]
  target_features: ["EMB-ESM", "EMB-NT"] 