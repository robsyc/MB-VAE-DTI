# Drug branch pretraining configuration for Full DTI model
# Uses contrastive + KL + reconstruction losses

model:
  phase: pretrain_drug
  
  # Dataset statistics for diffusion decoder (pre-computed from drugs dataset)
  # These will be overridden with actual values when available
  dataset_statistics:
    heavy_atom_counts:
      10: 1000
      11: 1200
      12: 1500
      13: 1800
      14: 2000
      15: 2200
      16: 2400
      17: 2500
      18: 2600
      19: 2700
      20: 2800
      21: 2700
      22: 2600
      23: 2500
      24: 2400
      25: 2200
      26: 2000
      27: 1800
      28: 1600
      29: 1400
      30: 1200
    max_heavy_atoms: 64
    max_mol_weight: 500.0
    atom_weights:
      0: 12.01  # C
      1: 16.00  # O
      2: 30.97  # P
      3: 14.01  # N
      4: 32.07  # S
      5: 35.45  # Cl
      6: 19.00  # F
      7: 1.01   # H
    valencies: [4, 2, 5, 3, 2, 1, 1, 1]
    x_marginals: [0.736, 0.131, 0.001, 0.107, 0.012, 0.003, 0.010, 0.000]
    e_marginals: [0.913, 0.044, 0.006, 0.0002, 0.037]
    atom_decoder: ['C', 'O', 'P', 'N', 'S', 'Cl', 'F', 'H']

# Data configuration
data:
  h5_path: /home/robsyc/Desktop/thesis/MB-VAE-DTI/data/input/drugs.h5torch
  drug_features: ['EMB-BiomedGraph', 'EMB-BiomedImg', 'EMB-BiomedText']
  target_features: null
  batch_size: 32
  num_workers: 4
  pin_memory: true
  shuffle_train: true
  drop_last: true
  load_in_memory: false

# Training configuration
training:
  max_epochs: 100
  learning_rate: 1e-4
  weight_decay: 1e-5
  early_stopping_patience: 20
  scheduler: cosine
  
# Logging configuration
logging:
  experiment_name: full_pretrain_drug

# Gridsearch parameters
gridsearch:
  training.learning_rate: [1e-3, 5e-4, 1e-4]
  model.kl_weight: [0.05, 0.1, 0.2]
  model.reconstruction_weight: [0.5, 1.0, 2.0]
  model.encoder_kwargs.dropout: [0.1, 0.2] 