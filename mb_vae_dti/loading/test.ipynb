{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from tdc.multi_pred import DTI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/home/robsyc/Desktop/thesis/MB-VAE-DTI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "smiles    CCCS(=O)c1ccc2[nH]c(=NC(=O)OC)[nH]c2c1\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = MolGen(name=\"MOSES\", path=\"./data/source/\")\n",
    "df = data.get_data()\n",
    "\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol = Chem.MolFromSmiles(\"CCCS(=O)c1ccc2[nH]c(=NC(=O)OC)[nH]c2c1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "Descriptors.HeavyAtomCount(mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MOSES...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "Found local copy...\n",
      "Loading...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1936962 molecules loaded\n",
      "Loading ZINC...\n",
      "  249455 molecules loaded\n",
      "Loading ChEMBL_V29...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2084723 molecules loaded\n",
      "Total molecules before deduplication: 4271140\n",
      "Unique molecules before canonicalization: 4181441\n",
      "Canonicalizing SMILES using 8 workers...\n",
      "  Processed 10/419 chunks\n",
      "  Processed 20/419 chunks\n",
      "  Processed 30/419 chunks\n",
      "  Processed 40/419 chunks\n",
      "  Processed 50/419 chunks\n",
      "  Processed 60/419 chunks\n",
      "  Processed 70/419 chunks\n",
      "  Processed 80/419 chunks\n",
      "  Processed 90/419 chunks\n",
      "  Processed 100/419 chunks\n",
      "  Processed 110/419 chunks\n",
      "  Processed 120/419 chunks\n",
      "  Processed 130/419 chunks\n",
      "  Processed 140/419 chunks\n",
      "  Processed 150/419 chunks\n",
      "  Processed 160/419 chunks\n",
      "  Processed 170/419 chunks\n",
      "  Processed 180/419 chunks\n",
      "  Processed 190/419 chunks\n",
      "  Processed 200/419 chunks\n",
      "  Processed 210/419 chunks\n",
      "  Processed 220/419 chunks\n",
      "  Processed 230/419 chunks\n",
      "  Processed 240/419 chunks\n",
      "  Processed 250/419 chunks\n",
      "  Processed 260/419 chunks\n",
      "  Processed 270/419 chunks\n",
      "  Processed 280/419 chunks\n",
      "  Processed 290/419 chunks\n",
      "  Processed 300/419 chunks\n",
      "  Processed 310/419 chunks\n",
      "  Processed 320/419 chunks\n",
      "  Processed 330/419 chunks\n",
      "  Processed 340/419 chunks\n",
      "  Processed 350/419 chunks\n",
      "  Processed 360/419 chunks\n",
      "  Processed 370/419 chunks\n",
      "  Processed 380/419 chunks\n",
      "  Processed 390/419 chunks\n",
      "  Processed 400/419 chunks\n",
      "  Processed 410/419 chunks\n",
      "Total valid molecules after processing: 4130685\n"
     ]
    }
   ],
   "source": [
    "from tdc.generation import MolGen\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from pathlib import Path\n",
    "import concurrent.futures\n",
    "import numpy as np\n",
    "\n",
    "# Define paths\n",
    "DATA_DIR = Path(\"data\")\n",
    "SOURCE_DIR = DATA_DIR / \"source\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "\n",
    "MAX_N_HEAVY_ATOMS = 64\n",
    "\n",
    "# Disable RDKit logging for better performance\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "def canonicalize_smiles(smiles):\n",
    "    \"\"\"Convert a SMILES string to its canonical form\"\"\"\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol and Descriptors.HeavyAtomCount(mol) <= MAX_N_HEAVY_ATOMS:\n",
    "            return Chem.MolToSmiles(mol, isomericSmiles=True)\n",
    "        return \"\"\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def process_chunk(smiles_chunk):\n",
    "    \"\"\"Process a chunk of SMILES strings in parallel\"\"\"\n",
    "    return [canonicalize_smiles(smiles) for smiles in smiles_chunk]\n",
    "\n",
    "def fetch_and_merge_datasets(datasets=[\"MOSES\", \"ZINC\", \"ChEMBL_V29\"], path=SOURCE_DIR, n_workers=8, chunk_size=10000):\n",
    "    \"\"\"\n",
    "    Fetches and merges multiple molecular datasets, removing duplicate SMILES\n",
    "    and ensuring all SMILES are in canonical form using RDKit with parallel processing.\n",
    "    \n",
    "    Args:\n",
    "        datasets (list): List of dataset names to fetch\n",
    "        path (str): Path to store/load the datasets\n",
    "        n_workers (int): Number of parallel workers\n",
    "        chunk_size (int): Size of chunks for parallel processing\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Merged dataframe with unique canonical SMILES\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    for dataset_name in datasets:\n",
    "        print(f\"Loading {dataset_name}...\")\n",
    "        data = MolGen(name=dataset_name, path=path)\n",
    "        df = data.get_data()\n",
    "        all_data.append(df)\n",
    "        print(f\"  {len(df)} molecules loaded\")\n",
    "    \n",
    "    # Concatenate all dataframes\n",
    "    merged_df = pd.concat(all_data, ignore_index=True)\n",
    "    print(f\"Total molecules before deduplication: {len(merged_df)}\")\n",
    "    \n",
    "    # First deduplication on exact SMILES strings\n",
    "    merged_df = merged_df.drop_duplicates(subset=['smiles'])\n",
    "    print(f\"Unique molecules before canonicalization: {len(merged_df)}\")\n",
    "    \n",
    "    # Split SMILES into chunks for parallel processing\n",
    "    smiles_list = merged_df['smiles'].tolist()\n",
    "    smiles_chunks = [smiles_list[i:i+chunk_size] for i in range(0, len(smiles_list), chunk_size)]\n",
    "    \n",
    "    # Use parallel processing for canonicalization\n",
    "    print(f\"Canonicalizing SMILES using {n_workers} workers...\")\n",
    "    canonical_smiles_chunks = []\n",
    "    \n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=n_workers) as executor:\n",
    "        # Submit all chunks for processing\n",
    "        future_to_chunk = {executor.submit(process_chunk, chunk): i for i, chunk in enumerate(smiles_chunks)}\n",
    "        \n",
    "        # Process results as they complete\n",
    "        for future in concurrent.futures.as_completed(future_to_chunk):\n",
    "            chunk_idx = future_to_chunk[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                canonical_smiles_chunks.append(result)\n",
    "                # Print progress\n",
    "                if (chunk_idx + 1) % 10 == 0:\n",
    "                    print(f\"  Processed {chunk_idx + 1}/{len(smiles_chunks)} chunks\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing chunk {chunk_idx}: {e}\")\n",
    "    \n",
    "    # Flatten the list of chunks\n",
    "    canonical_smiles = []\n",
    "    for chunk in canonical_smiles_chunks:\n",
    "        canonical_smiles.extend(chunk)\n",
    "    \n",
    "    # Add canonical SMILES to dataframe\n",
    "    merged_df['canonical_smiles'] = canonical_smiles\n",
    "\n",
    "    # Remove duplicates based on canonical SMILES and filter out invalid molecules\n",
    "    merged_df = merged_df[merged_df['canonical_smiles'] != \"\"]\n",
    "    unique_df = merged_df.drop_duplicates(subset=['canonical_smiles'])\n",
    "    \n",
    "    # Keep original column structure if needed\n",
    "    unique_df['smiles'] = unique_df['canonical_smiles']\n",
    "    unique_df.drop(columns=['canonical_smiles'], inplace=True)\n",
    "    \n",
    "    print(f\"Total valid molecules after processing: {len(unique_df)}\")\n",
    "    \n",
    "    return unique_df\n",
    "\n",
    "# Example usage\n",
    "datasets = [\"MOSES\", \"ZINC\", \"ChEMBL_V29\"]\n",
    "df = fetch_and_merge_datasets(datasets)\n",
    "df.to_csv(PROCESSED_DIR / \"data_drug_generation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCCS(=O)c1ccc2[nH]c(=NC(=O)OC)[nH]c2c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC(C)(C)C(=O)C(Oc1ccc(Cl)cc1)n1ccnc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC1C2CCC(C2)C1CN(CCO)C(=O)c1ccc(Cl)cc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cc1c(Cl)cccc1Nc1ncccc1C(=O)OCC(O)CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cn1cnc2c1c(=O)n(CC(O)CO)c(=O)n2C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4271135</th>\n",
       "      <td>CC(C)(C)c1cc(C(=O)NC2CCN(Cc3ccccc3)CC2)cc(C(C)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4271136</th>\n",
       "      <td>CCCCCCCCCOC[C@H]1O[C@H](O[C@@H]2[C@@H](O)[C@H]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4271137</th>\n",
       "      <td>COC(=O)[C@]12CC[C@@H](C(C)CO)[C@@H]1[C@H]1CC[C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4271138</th>\n",
       "      <td>COc1ccc(S(=O)(=O)NCc2ccc(C(=O)O)cc2)c2ccccc12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4271139</th>\n",
       "      <td>COc1cc(C(=O)/C=C/c2cc3c([nH]c4ccccc43)c(-c3cc(...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4130685 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    smiles\n",
       "0                   CCCS(=O)c1ccc2[nH]c(=NC(=O)OC)[nH]c2c1\n",
       "1                     CC(C)(C)C(=O)C(Oc1ccc(Cl)cc1)n1ccnc1\n",
       "2                   CC1C2CCC(C2)C1CN(CCO)C(=O)c1ccc(Cl)cc1\n",
       "3                      Cc1c(Cl)cccc1Nc1ncccc1C(=O)OCC(O)CO\n",
       "4                         Cn1cnc2c1c(=O)n(CC(O)CO)c(=O)n2C\n",
       "...                                                    ...\n",
       "4271135  CC(C)(C)c1cc(C(=O)NC2CCN(Cc3ccccc3)CC2)cc(C(C)...\n",
       "4271136  CCCCCCCCCOC[C@H]1O[C@H](O[C@@H]2[C@@H](O)[C@H]...\n",
       "4271137  COC(=O)[C@]12CC[C@@H](C(C)CO)[C@@H]1[C@H]1CC[C...\n",
       "4271138      COc1ccc(S(=O)(=O)NCc2ccc(C(=O)O)cc2)c2ccccc12\n",
       "4271139  COc1cc(C(=O)/C=C/c2cc3c([nH]c4ccccc43)c(-c3cc(...\n",
       "\n",
       "[4130685 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mbvae_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
