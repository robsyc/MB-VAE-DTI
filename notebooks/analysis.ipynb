{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>depth</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>latent_dim</th>\n",
       "      <th>dropout_prob</th>\n",
       "      <th>best_valid_loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>num_trainable_params</th>\n",
       "      <th>runtime</th>\n",
       "      <th>kl_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>single_view_fp_plain_-8054598309511539763</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.534829</td>\n",
       "      <td>0.600784</td>\n",
       "      <td>1173396</td>\n",
       "      <td>60.185689</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>single_view_emb_variational_5282197061669233432</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.937528</td>\n",
       "      <td>1.099271</td>\n",
       "      <td>792576</td>\n",
       "      <td>80.204371</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>multi_view_variational_4453866053670671622</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.832869</td>\n",
       "      <td>0.867915</td>\n",
       "      <td>5037206</td>\n",
       "      <td>213.371477</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>single_view_emb_variational_-7401032702674798705</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.622857</td>\n",
       "      <td>1.662488</td>\n",
       "      <td>432640</td>\n",
       "      <td>83.216578</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>single_view_fp_variational_-1614181474134004323</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.445021</td>\n",
       "      <td>0.478593</td>\n",
       "      <td>1007764</td>\n",
       "      <td>106.491475</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>single_view_fp_plain_-1363216830430859170</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.384676</td>\n",
       "      <td>0.395282</td>\n",
       "      <td>4514452</td>\n",
       "      <td>102.039744</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>single_view_fp_variational_6164373553531490582</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.535143</td>\n",
       "      <td>5.722931</td>\n",
       "      <td>1041300</td>\n",
       "      <td>71.915485</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>multi_view_variational_7392475774628741531</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.437350</td>\n",
       "      <td>0.487291</td>\n",
       "      <td>2670998</td>\n",
       "      <td>125.670840</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>single_view_emb_plain_-8030435951507706559</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.325011</td>\n",
       "      <td>0.460477</td>\n",
       "      <td>366592</td>\n",
       "      <td>105.231596</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>single_view_emb_plain_8398463583242479563</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.364252</td>\n",
       "      <td>0.521808</td>\n",
       "      <td>660992</td>\n",
       "      <td>48.325668</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>multi_view_variational_4095480545174965769</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.559440</td>\n",
       "      <td>0.576618</td>\n",
       "      <td>6094486</td>\n",
       "      <td>504.050156</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>multi_view_variational_-5733295172318032540</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.725822</td>\n",
       "      <td>0.872331</td>\n",
       "      <td>2670998</td>\n",
       "      <td>1069.121125</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>multi_view_variational_14300863748690597</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.391479</td>\n",
       "      <td>0.419017</td>\n",
       "      <td>2406294</td>\n",
       "      <td>381.107794</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>single_view_emb_variational_-5678191666357474469</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.449788</td>\n",
       "      <td>0.538728</td>\n",
       "      <td>2370560</td>\n",
       "      <td>85.138842</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>multi_view_variational_609749423644952704</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>512</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.515071</td>\n",
       "      <td>1.527925</td>\n",
       "      <td>18457750</td>\n",
       "      <td>171.199612</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>single_view_emb_variational_-6476988900417324114</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.631486</td>\n",
       "      <td>0.862325</td>\n",
       "      <td>2368512</td>\n",
       "      <td>116.570222</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>single_view_emb_variational_-4067304377454158167</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.918197</td>\n",
       "      <td>6.146915</td>\n",
       "      <td>1055744</td>\n",
       "      <td>117.299112</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>multi_view_variational_-5239878468762481526</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.485289</td>\n",
       "      <td>0.559470</td>\n",
       "      <td>13194902</td>\n",
       "      <td>156.349272</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>single_view_emb_variational_1422951838310337635</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.530816</td>\n",
       "      <td>0.561073</td>\n",
       "      <td>564736</td>\n",
       "      <td>100.699963</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>single_view_fp_variational_632951942277624003</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.458483</td>\n",
       "      <td>0.466686</td>\n",
       "      <td>2000532</td>\n",
       "      <td>85.918541</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          experiment  learning_rate  \\\n",
       "0          single_view_fp_plain_-8054598309511539763         0.0001   \n",
       "1    single_view_emb_variational_5282197061669233432         0.0010   \n",
       "2         multi_view_variational_4453866053670671622         0.0005   \n",
       "3   single_view_emb_variational_-7401032702674798705         0.0005   \n",
       "4    single_view_fp_variational_-1614181474134004323         0.0005   \n",
       "5          single_view_fp_plain_-1363216830430859170         0.0005   \n",
       "6     single_view_fp_variational_6164373553531490582         0.0005   \n",
       "7         multi_view_variational_7392475774628741531         0.0005   \n",
       "8         single_view_emb_plain_-8030435951507706559         0.0001   \n",
       "9          single_view_emb_plain_8398463583242479563         0.0010   \n",
       "10        multi_view_variational_4095480545174965769         0.0001   \n",
       "11       multi_view_variational_-5733295172318032540         0.0005   \n",
       "12          multi_view_variational_14300863748690597         0.0005   \n",
       "13  single_view_emb_variational_-5678191666357474469         0.0005   \n",
       "14         multi_view_variational_609749423644952704         0.0005   \n",
       "15  single_view_emb_variational_-6476988900417324114         0.0010   \n",
       "16  single_view_emb_variational_-4067304377454158167         0.0001   \n",
       "17       multi_view_variational_-5239878468762481526         0.0005   \n",
       "18   single_view_emb_variational_1422951838310337635         0.0001   \n",
       "19     single_view_fp_variational_632951942277624003         0.0010   \n",
       "\n",
       "    batch_size  depth  hidden_dim  latent_dim  dropout_prob  best_valid_loss  \\\n",
       "0           64      3         128        1024           0.1         0.534829   \n",
       "1          128      1         256         256           0.1         0.937528   \n",
       "2           32      1         256         256           0.3         0.832869   \n",
       "3           32      3         128         256           0.3         1.622857   \n",
       "4           32      2         128         256           0.3         0.445021   \n",
       "5           32      2         512         256           0.1         0.384676   \n",
       "6          128      3         128         256           0.1         5.535143   \n",
       "7           64      3         128         512           0.3         0.437350   \n",
       "8           64      3         128         256           0.3         0.325011   \n",
       "9          128      1         256         256           0.1         0.364252   \n",
       "10          32      2         256         512           0.1         0.559440   \n",
       "11          32      3         128         512           0.3         0.725822   \n",
       "12          32      3         128         256           0.3         0.391479   \n",
       "13         128      2         512         256           0.3         0.449788   \n",
       "14          64      2         512        1024           0.3         1.515071   \n",
       "15          32      1         512         512           0.1         0.631486   \n",
       "16         128      1         256         512           0.1         5.918197   \n",
       "17          32      1         512         256           0.3         0.485289   \n",
       "18          64      3         128         512           0.1         0.530816   \n",
       "19         128      1         256         256           0.3         0.458483   \n",
       "\n",
       "    test_loss  num_trainable_params      runtime  kl_weight  \n",
       "0    0.600784               1173396    60.185689        NaN  \n",
       "1    1.099271                792576    80.204371      0.010  \n",
       "2    0.867915               5037206   213.371477      0.010  \n",
       "3    1.662488                432640    83.216578      0.100  \n",
       "4    0.478593               1007764   106.491475      0.001  \n",
       "5    0.395282               4514452   102.039744        NaN  \n",
       "6    5.722931               1041300    71.915485      0.100  \n",
       "7    0.487291               2670998   125.670840      0.001  \n",
       "8    0.460477                366592   105.231596        NaN  \n",
       "9    0.521808                660992    48.325668        NaN  \n",
       "10   0.576618               6094486   504.050156      0.010  \n",
       "11   0.872331               2670998  1069.121125      0.100  \n",
       "12   0.419017               2406294   381.107794      0.001  \n",
       "13   0.538728               2370560    85.138842      0.001  \n",
       "14   1.527925              18457750   171.199612      0.010  \n",
       "15   0.862325               2368512   116.570222      0.010  \n",
       "16   6.146915               1055744   117.299112      0.100  \n",
       "17   0.559470              13194902   156.349272      0.001  \n",
       "18   0.561073                564736   100.699963      0.001  \n",
       "19   0.466686               2000532    85.918541      0.001  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "os.listdir(\"./results\")\n",
    "\n",
    "# ['single_view_fp_plain_-8054598309511539763.json',\n",
    "#  'single_view_emb_variational_5282197061669233432.json',\n",
    "#  'multi_view_variational_4453866053670671622.json',\n",
    "# ...\n",
    "\n",
    "# e.g.\n",
    "{\n",
    "    \"experiment\": \"multi_view_plain_-46151256717262646\",\n",
    "    \"learning_rate\": 0.0005,\n",
    "    \"batch_size\": 32,\n",
    "    \"depth\": 1,\n",
    "    \"hidden_dim\": 256,\n",
    "    \"latent_dim\": 256,\n",
    "    \"dropout_prob\": 0.3,\n",
    "    \"best_valid_loss\": 0.3437898400660655,\n",
    "    \"test_loss\": 0.3843511521654285,\n",
    "    \"num_trainable_params\": 4510870,\n",
    "    \"runtime\": 201.72464776039124\n",
    "}\n",
    "\n",
    "# Iterate over all json files in the results directory and create dataframe\n",
    "results = []\n",
    "for file in os.listdir(\"./results\"):\n",
    "    with open(f\"./results/{file}\") as f:\n",
    "        results.append(json.load(f))\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>depth</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>latent_dim</th>\n",
       "      <th>dropout_prob</th>\n",
       "      <th>best_valid_loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>num_trainable_params</th>\n",
       "      <th>runtime</th>\n",
       "      <th>kl_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4403</th>\n",
       "      <td>multi_view_plain_6889676395874673667</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.279012</td>\n",
       "      <td>0.388109</td>\n",
       "      <td>2538902</td>\n",
       "      <td>226.549141</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>multi_view_plain_-6980364999454184749</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.283760</td>\n",
       "      <td>0.380885</td>\n",
       "      <td>2934166</td>\n",
       "      <td>259.208587</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2709</th>\n",
       "      <td>multi_view_plain_-4039478511947688627</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.286358</td>\n",
       "      <td>0.400966</td>\n",
       "      <td>2404758</td>\n",
       "      <td>211.198660</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3927</th>\n",
       "      <td>multi_view_plain_-1152802831377065867</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.290226</td>\n",
       "      <td>0.394491</td>\n",
       "      <td>2934166</td>\n",
       "      <td>71.499071</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>multi_view_plain_121099320718851654</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.293108</td>\n",
       "      <td>0.389307</td>\n",
       "      <td>2140054</td>\n",
       "      <td>213.675427</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5008</th>\n",
       "      <td>multi_view_plain_5510231668160124536</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.294341</td>\n",
       "      <td>0.420666</td>\n",
       "      <td>4510870</td>\n",
       "      <td>249.576968</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1838</th>\n",
       "      <td>multi_view_plain_-4067751348410180787</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.295221</td>\n",
       "      <td>0.396528</td>\n",
       "      <td>3068310</td>\n",
       "      <td>180.527764</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>multi_view_plain_-2749008768293101802</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.295709</td>\n",
       "      <td>0.367693</td>\n",
       "      <td>2140054</td>\n",
       "      <td>177.851590</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>single_view_emb_plain_8658592234400222681</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.298029</td>\n",
       "      <td>0.482521</td>\n",
       "      <td>399104</td>\n",
       "      <td>104.644583</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>multi_view_plain_-4446959247277792444</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.299130</td>\n",
       "      <td>0.366866</td>\n",
       "      <td>2404758</td>\n",
       "      <td>170.107697</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372</th>\n",
       "      <td>multi_view_plain_1889584770367513694</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.299179</td>\n",
       "      <td>0.372348</td>\n",
       "      <td>5568150</td>\n",
       "      <td>161.058759</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3428</th>\n",
       "      <td>multi_view_plain_-2398525922477981059</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.299208</td>\n",
       "      <td>0.372942</td>\n",
       "      <td>3068310</td>\n",
       "      <td>140.831977</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4188</th>\n",
       "      <td>multi_view_plain_2595612243134201407</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.299847</td>\n",
       "      <td>0.367567</td>\n",
       "      <td>6091414</td>\n",
       "      <td>166.219586</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2601</th>\n",
       "      <td>single_view_emb_plain_4622942072648596796</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.300386</td>\n",
       "      <td>0.445779</td>\n",
       "      <td>432640</td>\n",
       "      <td>132.701605</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3279</th>\n",
       "      <td>multi_view_plain_3754422327244815066</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.300534</td>\n",
       "      <td>0.406376</td>\n",
       "      <td>2800022</td>\n",
       "      <td>222.810584</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2589</th>\n",
       "      <td>multi_view_plain_8571074180370853502</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.300831</td>\n",
       "      <td>0.382173</td>\n",
       "      <td>5041302</td>\n",
       "      <td>268.991783</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>multi_view_plain_4480558795015430237</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.301067</td>\n",
       "      <td>0.382321</td>\n",
       "      <td>2140054</td>\n",
       "      <td>215.497025</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>multi_view_plain_-7575678135182282380</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.301542</td>\n",
       "      <td>0.360872</td>\n",
       "      <td>6098582</td>\n",
       "      <td>242.893220</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>multi_view_plain_8557252163537466948</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>512</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.302563</td>\n",
       "      <td>0.394633</td>\n",
       "      <td>16356502</td>\n",
       "      <td>171.967917</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5101</th>\n",
       "      <td>multi_view_plain_7575332558046709992</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.302952</td>\n",
       "      <td>0.382158</td>\n",
       "      <td>2800022</td>\n",
       "      <td>50.868868</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     experiment  learning_rate  batch_size  \\\n",
       "4403       multi_view_plain_6889676395874673667         0.0010         128   \n",
       "1854      multi_view_plain_-6980364999454184749         0.0005          64   \n",
       "2709      multi_view_plain_-4039478511947688627         0.0005         128   \n",
       "3927      multi_view_plain_-1152802831377065867         0.0010         128   \n",
       "2084        multi_view_plain_121099320718851654         0.0005          64   \n",
       "5008       multi_view_plain_5510231668160124536         0.0005         128   \n",
       "1838      multi_view_plain_-4067751348410180787         0.0005          64   \n",
       "1469      multi_view_plain_-2749008768293101802         0.0010          64   \n",
       "1560  single_view_emb_plain_8658592234400222681         0.0001          64   \n",
       "201       multi_view_plain_-4446959247277792444         0.0005          64   \n",
       "2372       multi_view_plain_1889584770367513694         0.0005          64   \n",
       "3428      multi_view_plain_-2398525922477981059         0.0010          64   \n",
       "4188       multi_view_plain_2595612243134201407         0.0005          64   \n",
       "2601  single_view_emb_plain_4622942072648596796         0.0001          64   \n",
       "3279       multi_view_plain_3754422327244815066         0.0010          64   \n",
       "2589       multi_view_plain_8571074180370853502         0.0010         128   \n",
       "2732       multi_view_plain_4480558795015430237         0.0005          64   \n",
       "940       multi_view_plain_-7575678135182282380         0.0005          32   \n",
       "706        multi_view_plain_8557252163537466948         0.0001         128   \n",
       "5101       multi_view_plain_7575332558046709992         0.0001         128   \n",
       "\n",
       "      depth  hidden_dim  latent_dim  dropout_prob  best_valid_loss  test_loss  \\\n",
       "4403      3         128         512           0.3         0.279012   0.388109   \n",
       "1854      2         128        1024           0.3         0.283760   0.380885   \n",
       "2709      2         128         512           0.3         0.286358   0.400966   \n",
       "3927      2         128        1024           0.1         0.290226   0.394491   \n",
       "2084      2         128         256           0.1         0.293108   0.389307   \n",
       "5008      1         256         256           0.3         0.294341   0.420666   \n",
       "1838      3         128        1024           0.3         0.295221   0.396528   \n",
       "1469      2         128         256           0.1         0.295709   0.367693   \n",
       "1560      2         128         512           0.3         0.298029   0.482521   \n",
       "201       2         128         512           0.3         0.299130   0.366866   \n",
       "2372      2         256         512           0.3         0.299179   0.372348   \n",
       "3428      3         128        1024           0.3         0.299208   0.372942   \n",
       "4188      1         256        1024           0.3         0.299847   0.367567   \n",
       "2601      3         128         512           0.3         0.300386   0.445779   \n",
       "3279      1         128        1024           0.1         0.300534   0.406376   \n",
       "2589      2         256         256           0.3         0.300831   0.382173   \n",
       "2732      2         128         256           0.3         0.301067   0.382321   \n",
       "940       3         256         512           0.1         0.301542   0.360872   \n",
       "706       2         512        1024           0.1         0.302563   0.394633   \n",
       "5101      1         128        1024           0.1         0.302952   0.382158   \n",
       "\n",
       "      num_trainable_params     runtime  kl_weight  \n",
       "4403               2538902  226.549141        NaN  \n",
       "1854               2934166  259.208587        NaN  \n",
       "2709               2404758  211.198660        NaN  \n",
       "3927               2934166   71.499071        NaN  \n",
       "2084               2140054  213.675427        NaN  \n",
       "5008               4510870  249.576968        NaN  \n",
       "1838               3068310  180.527764        NaN  \n",
       "1469               2140054  177.851590        NaN  \n",
       "1560                399104  104.644583        NaN  \n",
       "201                2404758  170.107697        NaN  \n",
       "2372               5568150  161.058759        NaN  \n",
       "3428               3068310  140.831977        NaN  \n",
       "4188               6091414  166.219586        NaN  \n",
       "2601                432640  132.701605        NaN  \n",
       "3279               2800022  222.810584        NaN  \n",
       "2589               5041302  268.991783        NaN  \n",
       "2732               2140054  215.497025        NaN  \n",
       "940                6098582  242.893220        NaN  \n",
       "706               16356502  171.967917        NaN  \n",
       "5101               2800022   50.868868        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort by best validation loss\n",
    "df.sort_values(\"best_valid_loss\").head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate\n",
      "0.0001    52\n",
      "0.0005    35\n",
      "0.0010    13\n",
      "Name: count, dtype: int64\n",
      "batch_size\n",
      "32     71\n",
      "64     24\n",
      "128     5\n",
      "Name: count, dtype: int64\n",
      "depth\n",
      "1    38\n",
      "2    33\n",
      "3    29\n",
      "Name: count, dtype: int64\n",
      "hidden_dim\n",
      "128    65\n",
      "256    24\n",
      "512    11\n",
      "Name: count, dtype: int64\n",
      "latent_dim\n",
      "256     42\n",
      "512     32\n",
      "1024    26\n",
      "Name: count, dtype: int64\n",
      "dropout_prob\n",
      "0.1    57\n",
      "0.3    43\n",
      "Name: count, dtype: int64\n",
      "kl_weight\n",
      "0.001    96\n",
      "0.100     4\n",
      "Name: count, dtype: int64\n",
      "330.3722142481804\n"
     ]
    }
   ],
   "source": [
    "subdf = df[df[\"experiment\"].str.contains(\"multi_view_variational\")].sort_values(\"best_valid_loss\").iloc[:100]\n",
    "\n",
    "for item in [\"learning_rate\", \"batch_size\", \"depth\", \"hidden_dim\", \"latent_dim\", \"dropout_prob\", \"kl_weight\"]:\n",
    "    print(subdf[item].value_counts())\n",
    "\n",
    "# give avg runtime\n",
    "print(subdf[\"runtime\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62298394842885"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE = 0.388109\n",
    "root_MSE = MSE ** 0.5\n",
    "root_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 60, 60])\n",
      "torch.Size([32, 256])\n",
      "torch.Size([32, 3540])\n",
      "torch.Size([32, 1770, 2])\n",
      "torch.Size([32, 1770])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 60, 60])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# adj batch_size x num_nodes x num_nodes\n",
    "num_nodes = 60\n",
    "batch_size = 32\n",
    "hidden_dim = 256\n",
    "x = torch.randn(batch_size, hidden_dim)\n",
    "adj = torch.randn(batch_size, num_nodes, num_nodes)\n",
    "print(adj.shape)\n",
    "print(x.shape)\n",
    "\n",
    "to_adj = nn.Linear(hidden_dim, 2*num_nodes*(num_nodes-1)//2)\n",
    "\n",
    "x = to_adj(x)\n",
    "print(x.shape)\n",
    "x = torch.reshape(x, (x.size(0), -1, 2))\n",
    "print(x.shape)\n",
    "x = F.gumbel_softmax(x, tau=1, hard=True)[:,:,0]\n",
    "print(x.shape)\n",
    "\n",
    "adj = torch.zeros(x.size(0), num_nodes, num_nodes)   # initialize adjacency matrix\n",
    "idx = torch.triu_indices(num_nodes, num_nodes, 1)                     # get upper triangular indices\n",
    "adj[:,idx[0],idx[1]] = x                              # fill in upper triangular part\n",
    "adj = adj + torch.transpose(adj, 1, 2)                                      # make symmetric\n",
    "adj.shape # (batch_size, n_nodes, n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  ..., 57, 57, 58],\n",
       "        [ 1,  2,  3,  ..., 58, 59, 59]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0.,  ..., 1., 0., 0.],\n",
       "        [1., 1., 0.,  ..., 1., 0., 0.],\n",
       "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 1.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 1., 1.,  ..., 1., 1., 1.]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1770"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "60*59//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1770"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nodes*(num_nodes-1)//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "60*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3600])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj.view(x.size(0), -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1364, -0.3604, -1.8680,  ..., -0.4514,  1.6060,  1.2494],\n",
       "         [ 0.3040, -3.0094,  1.1780,  ...,  0.7238,  0.9798,  2.0547],\n",
       "         [-1.0952,  1.3516,  1.1619,  ..., -1.5530, -0.6029,  0.6771],\n",
       "         ...,\n",
       "         [-0.3432,  0.0144, -2.3176,  ..., -1.4380, -0.8211,  0.5559],\n",
       "         [ 1.7502,  1.9408, -0.3727,  ...,  1.1111, -0.3406,  0.9098],\n",
       "         [-0.9984, -0.4357, -2.2276,  ...,  1.3976, -0.0488, -1.7852]],\n",
       "\n",
       "        [[-1.8168, -0.5372,  1.7354,  ..., -0.0310, -0.8994, -0.6736],\n",
       "         [ 0.5633, -0.3980, -0.2511,  ..., -1.6547,  1.0410,  0.0226],\n",
       "         [ 0.7749, -1.4277,  0.2565,  ...,  1.4209, -0.0270, -0.2470],\n",
       "         ...,\n",
       "         [ 0.7217,  0.0438, -1.5403,  ..., -0.7871, -0.3613,  0.3442],\n",
       "         [ 0.9818, -0.5376,  0.5828,  ..., -0.5802, -0.7084,  0.6669],\n",
       "         [-0.4688,  1.3937,  1.0418,  ..., -0.0287,  0.2791, -0.5498]],\n",
       "\n",
       "        [[ 0.8040, -0.1471, -0.4128,  ...,  0.7954, -0.5344, -0.3658],\n",
       "         [-1.2603, -1.0739, -1.5132,  ..., -0.4421, -0.1552, -1.2218],\n",
       "         [ 1.8732,  0.6387, -0.3102,  ..., -1.4078, -1.2357, -2.2121],\n",
       "         ...,\n",
       "         [-1.3079, -0.9739,  0.9755,  ...,  0.6648,  0.9113,  0.7581],\n",
       "         [-0.7691, -0.2994,  1.2032,  ..., -0.5046, -0.3267, -2.2224],\n",
       "         [-0.4997,  1.2743, -0.3688,  ...,  0.5001, -0.0583,  0.2385]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.3120,  0.6777, -0.4339,  ...,  0.0843, -0.7350, -1.5141],\n",
       "         [ 1.2702, -0.8920, -0.5297,  ..., -0.3330,  0.0151,  0.8263],\n",
       "         [ 0.5210, -0.9309,  0.1870,  ..., -0.8303, -0.2842,  0.3682],\n",
       "         ...,\n",
       "         [-1.9410,  0.5682,  0.0656,  ...,  1.3899,  0.3390,  0.9331],\n",
       "         [ 0.6034, -0.2716,  2.6251,  ..., -1.2203,  0.2121, -0.0986],\n",
       "         [ 0.7237,  0.8486, -1.7445,  ..., -0.5850,  0.8037,  1.5060]],\n",
       "\n",
       "        [[ 0.0502,  0.3243, -0.4212,  ...,  1.5448,  0.2214, -0.0466],\n",
       "         [-0.3026,  1.9630, -0.4114,  ...,  0.5849,  0.4378,  1.9621],\n",
       "         [-0.9117, -0.7249, -0.7983,  ..., -0.1869, -1.3458,  0.1356],\n",
       "         ...,\n",
       "         [ 0.1734,  1.6253, -2.3122,  ...,  0.5945, -0.8005, -1.1416],\n",
       "         [-1.2235, -1.7158,  0.9745,  ...,  1.1600, -1.1102, -1.0227],\n",
       "         [-0.8936, -1.8763, -0.1760,  ..., -2.1732, -1.0092, -0.4477]],\n",
       "\n",
       "        [[-1.0273,  0.1098, -1.9215,  ...,  0.3757, -0.5598, -1.4308],\n",
       "         [ 0.3393,  0.2611,  1.3342,  ..., -0.7325,  2.4258, -0.3671],\n",
       "         [-1.7513, -1.5158,  0.6610,  ..., -0.0593, -1.1090,  1.0353],\n",
       "         ...,\n",
       "         [ 0.1156, -1.2618, -1.8167,  ..., -0.7222,  1.4211,  1.2150],\n",
       "         [-1.5768,  0.1489,  0.6716,  ...,  0.9617, -1.3612,  1.1062],\n",
       "         [ 0.8586,  0.5585,  0.9659,  ..., -0.9946, -0.9502,  0.5009]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mbvae_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
