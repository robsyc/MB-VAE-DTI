{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Experiments were conducted using:\n",
    "- `mb_vae_dti/training/run.py`: command line interface for training\n",
    "- and the scripts in `scripts/training/` for running the experiments\n",
    "\n",
    "This notebook shows some plots and analysis of the unsupervised pretraining, general DTI training and benchmark fine-tuning results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting working directory to: /home/robsyc/Desktop/thesis/MB-VAE-DTI\n"
     ]
    }
   ],
   "source": [
    "from resolve import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-01 16:33:32,569 - mb_vae_dti.validating.analysis - INFO - Loading 128 result files from notebooks/results/multimodal_kiba_cold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/loss              0.4120\n",
      "test/Y_KIBA_ci         0.7243\n",
      "test/Y_KIBA_mse        0.4120\n",
      "test/Y_KIBA_pearson    0.5824\n",
      "test/Y_KIBA_r2         0.3210\n",
      "test/Y_KIBA_rmse       0.6418\n",
      "dtype: float64\n",
      "Params: 31.1M\n"
     ]
    }
   ],
   "source": [
    "from mb_vae_dti.validating.analysis import *\n",
    "\n",
    "df = load_gridsearch_results(\"notebooks/results/multimodal_kiba_cold/\")\n",
    "\n",
    "top_5 = df.sort_values(by=\"best_val_loss\", ascending=True).head(5)\n",
    "print(round(get_test_averages(top_5), 4))\n",
    "print(f\"Params: {top_5['trainable_params'].mean() / 1000000:.1f}M\")\n",
    "\n",
    "# # get subsets with desired distinction (encoder_type and aggregator_type)\n",
    "# with_resnet = df[df[\"config.model.encoder_type\"] == \"resnet\"]\n",
    "# with_transformer = df[df[\"config.model.encoder_type\"] == \"transformer\"]\n",
    "\n",
    "# # get 5 best performers\n",
    "# with_resnet_best = with_resnet.sort_values(by=\"best_val_loss\", ascending=True).head(5)\n",
    "# with_transformer_best = with_transformer.sort_values(by=\"best_val_loss\", ascending=True).head(5)\n",
    "\n",
    "# # get stats\n",
    "# print(f\"Params: {with_resnet_best['trainable_params'].mean() / 1000000:.1f}M\")\n",
    "# print(get_test_averages(with_resnet_best))\n",
    "# print(\"-\" * 100)\n",
    "# print(f\"Params: {with_transformer_best['trainable_params'].mean() / 1000000:.1f}M\")\n",
    "# print(get_test_averages(with_transformer_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>best_val_loss</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>trainable_params</th>\n",
       "      <th>val/loss</th>\n",
       "      <th>val/Y_KIBA_ci</th>\n",
       "      <th>val/Y_KIBA_mse</th>\n",
       "      <th>val/Y_KIBA_pearson</th>\n",
       "      <th>val/Y_KIBA_r2</th>\n",
       "      <th>val/Y_KIBA_rmse</th>\n",
       "      <th>...</th>\n",
       "      <th>config.loss.weights</th>\n",
       "      <th>config.data.batch_size</th>\n",
       "      <th>config.data.h5_path</th>\n",
       "      <th>config.data.drug_features</th>\n",
       "      <th>config.data.target_features</th>\n",
       "      <th>config.model.embedding_dim</th>\n",
       "      <th>config.model.hidden_dim</th>\n",
       "      <th>config.model.n_layers</th>\n",
       "      <th>config.model.dropout</th>\n",
       "      <th>config.model.encoder_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>baseline_finetune_KIBA_rand_b01c0031</td>\n",
       "      <td>0.161267</td>\n",
       "      <td>79</td>\n",
       "      <td>16316416</td>\n",
       "      <td>0.161267</td>\n",
       "      <td>0.857237</td>\n",
       "      <td>0.161267</td>\n",
       "      <td>0.871949</td>\n",
       "      <td>0.759009</td>\n",
       "      <td>0.477624</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>32</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>resnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>baseline_finetune_KIBA_rand_b00c0013</td>\n",
       "      <td>0.161339</td>\n",
       "      <td>91</td>\n",
       "      <td>17112832</td>\n",
       "      <td>0.161339</td>\n",
       "      <td>0.857617</td>\n",
       "      <td>0.161339</td>\n",
       "      <td>0.872011</td>\n",
       "      <td>0.758971</td>\n",
       "      <td>0.491604</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>64</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baseline_finetune_KIBA_rand_b01c0004</td>\n",
       "      <td>0.161553</td>\n",
       "      <td>84</td>\n",
       "      <td>16579072</td>\n",
       "      <td>0.161553</td>\n",
       "      <td>0.855682</td>\n",
       "      <td>0.161553</td>\n",
       "      <td>0.871681</td>\n",
       "      <td>0.758581</td>\n",
       "      <td>0.497610</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>32</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>768</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>resnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>baseline_finetune_KIBA_rand_b01c0015</td>\n",
       "      <td>0.161686</td>\n",
       "      <td>85</td>\n",
       "      <td>17375488</td>\n",
       "      <td>0.161686</td>\n",
       "      <td>0.854779</td>\n",
       "      <td>0.161686</td>\n",
       "      <td>0.871624</td>\n",
       "      <td>0.758382</td>\n",
       "      <td>0.480765</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>32</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>768</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>baseline_finetune_KIBA_rand_b00c0025</td>\n",
       "      <td>0.161989</td>\n",
       "      <td>82</td>\n",
       "      <td>17112832</td>\n",
       "      <td>0.161989</td>\n",
       "      <td>0.857333</td>\n",
       "      <td>0.161989</td>\n",
       "      <td>0.871524</td>\n",
       "      <td>0.757931</td>\n",
       "      <td>0.480886</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>32</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         experiment_name  best_val_loss  best_epoch  \\\n",
       "26  baseline_finetune_KIBA_rand_b01c0031       0.161267          79   \n",
       "38  baseline_finetune_KIBA_rand_b00c0013       0.161339          91   \n",
       "3   baseline_finetune_KIBA_rand_b01c0004       0.161553          84   \n",
       "13  baseline_finetune_KIBA_rand_b01c0015       0.161686          85   \n",
       "34  baseline_finetune_KIBA_rand_b00c0025       0.161989          82   \n",
       "\n",
       "    trainable_params  val/loss  val/Y_KIBA_ci  val/Y_KIBA_mse  \\\n",
       "26          16316416  0.161267       0.857237        0.161267   \n",
       "38          17112832  0.161339       0.857617        0.161339   \n",
       "3           16579072  0.161553       0.855682        0.161553   \n",
       "13          17375488  0.161686       0.854779        0.161686   \n",
       "34          17112832  0.161989       0.857333        0.161989   \n",
       "\n",
       "    val/Y_KIBA_pearson  val/Y_KIBA_r2  val/Y_KIBA_rmse  ...  \\\n",
       "26            0.871949       0.759009         0.477624  ...   \n",
       "38            0.872011       0.758971         0.491604  ...   \n",
       "3             0.871681       0.758581         0.497610  ...   \n",
       "13            0.871624       0.758382         0.480765  ...   \n",
       "34            0.871524       0.757931         0.480886  ...   \n",
       "\n",
       "    config.loss.weights  config.data.batch_size     config.data.h5_path  \\\n",
       "26              1_0_0_0                      32  data/input/dti.h5torch   \n",
       "38              1_0_0_0                      64  data/input/dti.h5torch   \n",
       "3               1_0_0_0                      32  data/input/dti.h5torch   \n",
       "13              1_0_0_0                      32  data/input/dti.h5torch   \n",
       "34              1_0_0_0                      32  data/input/dti.h5torch   \n",
       "\n",
       "    config.data.drug_features  config.data.target_features  \\\n",
       "26                  FP-Morgan                       FP-ESP   \n",
       "38                  FP-Morgan                       FP-ESP   \n",
       "3                   FP-Morgan                       FP-ESP   \n",
       "13                  FP-Morgan                       FP-ESP   \n",
       "34                  FP-Morgan                       FP-ESP   \n",
       "\n",
       "    config.model.embedding_dim  config.model.hidden_dim  \\\n",
       "26                         512                      512   \n",
       "38                         512                      512   \n",
       "3                          768                      512   \n",
       "13                         768                      512   \n",
       "34                         512                      512   \n",
       "\n",
       "    config.model.n_layers  config.model.dropout  config.model.encoder_type  \n",
       "26                      3                   0.1                     resnet  \n",
       "38                      3                   0.1                transformer  \n",
       "3                       3                   0.1                     resnet  \n",
       "13                      3                   0.1                transformer  \n",
       "34                      3                   0.1                transformer  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>best_val_loss</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>trainable_params</th>\n",
       "      <th>val/loss</th>\n",
       "      <th>val/Y_pKd_ci</th>\n",
       "      <th>val/Y_pKd_mse</th>\n",
       "      <th>val/Y_pKd_pearson</th>\n",
       "      <th>val/Y_pKd_r2</th>\n",
       "      <th>val/Y_pKd_rmse</th>\n",
       "      <th>...</th>\n",
       "      <th>config.loss.weights</th>\n",
       "      <th>config.data.batch_size</th>\n",
       "      <th>config.data.h5_path</th>\n",
       "      <th>config.data.drug_features</th>\n",
       "      <th>config.data.target_features</th>\n",
       "      <th>config.model.embedding_dim</th>\n",
       "      <th>config.model.hidden_dim</th>\n",
       "      <th>config.model.n_layers</th>\n",
       "      <th>config.model.dropout</th>\n",
       "      <th>config.model.encoder_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multi_output_finetune_DAVIS_cold_b00c0002</td>\n",
       "      <td>0.404908</td>\n",
       "      <td>0</td>\n",
       "      <td>27476741</td>\n",
       "      <td>0.724740</td>\n",
       "      <td>0.778565</td>\n",
       "      <td>0.724740</td>\n",
       "      <td>0.625569</td>\n",
       "      <td>0.082744</td>\n",
       "      <td>0.848325</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>16</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>multi_output_finetune_DAVIS_cold_b00c0008</td>\n",
       "      <td>0.226926</td>\n",
       "      <td>0</td>\n",
       "      <td>27476741</td>\n",
       "      <td>0.706371</td>\n",
       "      <td>0.777105</td>\n",
       "      <td>0.706371</td>\n",
       "      <td>0.624257</td>\n",
       "      <td>0.105999</td>\n",
       "      <td>0.822966</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>64</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>multi_output_finetune_DAVIS_cold_b00c0003</td>\n",
       "      <td>0.226926</td>\n",
       "      <td>0</td>\n",
       "      <td>27476741</td>\n",
       "      <td>2.054697</td>\n",
       "      <td>0.774795</td>\n",
       "      <td>2.054697</td>\n",
       "      <td>0.626279</td>\n",
       "      <td>-1.600477</td>\n",
       "      <td>1.394190</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>64</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.50</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>multi_output_finetune_DAVIS_cold_b00c0026</td>\n",
       "      <td>0.404908</td>\n",
       "      <td>0</td>\n",
       "      <td>27476741</td>\n",
       "      <td>2.253255</td>\n",
       "      <td>0.775438</td>\n",
       "      <td>2.253255</td>\n",
       "      <td>0.626443</td>\n",
       "      <td>-1.851798</td>\n",
       "      <td>1.491265</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>16</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.50</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>multi_output_finetune_DAVIS_cold_b00c0005</td>\n",
       "      <td>0.226926</td>\n",
       "      <td>0</td>\n",
       "      <td>27476741</td>\n",
       "      <td>0.673331</td>\n",
       "      <td>0.776668</td>\n",
       "      <td>0.673331</td>\n",
       "      <td>0.621355</td>\n",
       "      <td>0.147815</td>\n",
       "      <td>0.803889</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>64</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>multi_output_finetune_DAVIS_cold_b00c0024</td>\n",
       "      <td>0.404908</td>\n",
       "      <td>0</td>\n",
       "      <td>27476741</td>\n",
       "      <td>0.690506</td>\n",
       "      <td>0.776527</td>\n",
       "      <td>0.690506</td>\n",
       "      <td>0.622077</td>\n",
       "      <td>0.126071</td>\n",
       "      <td>0.828231</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>16</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>multi_output_finetune_DAVIS_cold_b00c0023</td>\n",
       "      <td>0.355166</td>\n",
       "      <td>0</td>\n",
       "      <td>27476741</td>\n",
       "      <td>1.837927</td>\n",
       "      <td>0.772699</td>\n",
       "      <td>1.837927</td>\n",
       "      <td>0.624967</td>\n",
       "      <td>-1.326121</td>\n",
       "      <td>1.338478</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>32</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.50</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>multi_output_finetune_DAVIS_cold_b00c0007</td>\n",
       "      <td>0.404908</td>\n",
       "      <td>0</td>\n",
       "      <td>27476741</td>\n",
       "      <td>0.979110</td>\n",
       "      <td>0.778651</td>\n",
       "      <td>0.979110</td>\n",
       "      <td>0.626377</td>\n",
       "      <td>-0.239195</td>\n",
       "      <td>0.984877</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>16</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>multi_output_finetune_DAVIS_cold_b00c0000</td>\n",
       "      <td>0.226926</td>\n",
       "      <td>0</td>\n",
       "      <td>27476741</td>\n",
       "      <td>0.950711</td>\n",
       "      <td>0.777043</td>\n",
       "      <td>0.950711</td>\n",
       "      <td>0.625307</td>\n",
       "      <td>-0.203244</td>\n",
       "      <td>0.952252</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>64</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>multi_output_finetune_DAVIS_cold_b00c0012</td>\n",
       "      <td>0.404908</td>\n",
       "      <td>0</td>\n",
       "      <td>27476741</td>\n",
       "      <td>0.916460</td>\n",
       "      <td>0.776402</td>\n",
       "      <td>0.916460</td>\n",
       "      <td>0.621097</td>\n",
       "      <td>-0.159903</td>\n",
       "      <td>0.953062</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>16</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>multi_output_finetune_DAVIS_cold_b00c0020</td>\n",
       "      <td>0.355166</td>\n",
       "      <td>0</td>\n",
       "      <td>27476741</td>\n",
       "      <td>0.726738</td>\n",
       "      <td>0.779338</td>\n",
       "      <td>0.726738</td>\n",
       "      <td>0.625715</td>\n",
       "      <td>0.080225</td>\n",
       "      <td>0.845641</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>32</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>multi_output_finetune_DAVIS_cold_b00c0016</td>\n",
       "      <td>0.404908</td>\n",
       "      <td>0</td>\n",
       "      <td>27476741</td>\n",
       "      <td>1.663292</td>\n",
       "      <td>0.775007</td>\n",
       "      <td>1.663292</td>\n",
       "      <td>0.617334</td>\n",
       "      <td>-1.105120</td>\n",
       "      <td>1.281908</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>16</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.50</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>multi_output_finetune_DAVIS_cold_b00c0011</td>\n",
       "      <td>0.404908</td>\n",
       "      <td>0</td>\n",
       "      <td>27476741</td>\n",
       "      <td>0.751307</td>\n",
       "      <td>0.780759</td>\n",
       "      <td>0.751307</td>\n",
       "      <td>0.627797</td>\n",
       "      <td>0.049120</td>\n",
       "      <td>0.863598</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>16</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>multi_output_finetune_DAVIS_cold_b00c0009</td>\n",
       "      <td>0.355166</td>\n",
       "      <td>0</td>\n",
       "      <td>27476741</td>\n",
       "      <td>0.991794</td>\n",
       "      <td>0.779585</td>\n",
       "      <td>0.991794</td>\n",
       "      <td>0.628807</td>\n",
       "      <td>-0.255237</td>\n",
       "      <td>0.985835</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>32</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>multi_output_finetune_DAVIS_cold_b00c0022</td>\n",
       "      <td>0.226926</td>\n",
       "      <td>0</td>\n",
       "      <td>27476741</td>\n",
       "      <td>1.295194</td>\n",
       "      <td>0.776756</td>\n",
       "      <td>1.295194</td>\n",
       "      <td>0.616853</td>\n",
       "      <td>-0.639230</td>\n",
       "      <td>1.109215</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>64</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.50</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>multi_output_finetune_DAVIS_cold_b00c0004</td>\n",
       "      <td>0.404908</td>\n",
       "      <td>0</td>\n",
       "      <td>27476741</td>\n",
       "      <td>1.005264</td>\n",
       "      <td>0.781399</td>\n",
       "      <td>1.005264</td>\n",
       "      <td>0.629576</td>\n",
       "      <td>-0.272297</td>\n",
       "      <td>0.997858</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>16</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>multi_output_finetune_DAVIS_cold_b00c0015</td>\n",
       "      <td>0.355166</td>\n",
       "      <td>0</td>\n",
       "      <td>27476741</td>\n",
       "      <td>0.955632</td>\n",
       "      <td>0.777232</td>\n",
       "      <td>0.955632</td>\n",
       "      <td>0.626144</td>\n",
       "      <td>-0.209469</td>\n",
       "      <td>0.967905</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>32</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>multi_output_finetune_DAVIS_cold_b00c0018</td>\n",
       "      <td>0.226926</td>\n",
       "      <td>0</td>\n",
       "      <td>27476741</td>\n",
       "      <td>0.983933</td>\n",
       "      <td>0.777134</td>\n",
       "      <td>0.983933</td>\n",
       "      <td>0.626870</td>\n",
       "      <td>-0.245290</td>\n",
       "      <td>0.968498</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>64</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>multi_output_finetune_DAVIS_cold_b00c0019</td>\n",
       "      <td>0.355166</td>\n",
       "      <td>0</td>\n",
       "      <td>27476741</td>\n",
       "      <td>0.884318</td>\n",
       "      <td>0.776187</td>\n",
       "      <td>0.884318</td>\n",
       "      <td>0.620627</td>\n",
       "      <td>-0.119213</td>\n",
       "      <td>0.931535</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>32</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>multi_output_finetune_DAVIS_cold_b00c0001</td>\n",
       "      <td>0.355166</td>\n",
       "      <td>0</td>\n",
       "      <td>27476741</td>\n",
       "      <td>0.733412</td>\n",
       "      <td>0.777101</td>\n",
       "      <td>0.733412</td>\n",
       "      <td>0.623312</td>\n",
       "      <td>0.071778</td>\n",
       "      <td>0.849455</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>32</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>multi_output_finetune_DAVIS_cold_b00c0014</td>\n",
       "      <td>0.226926</td>\n",
       "      <td>0</td>\n",
       "      <td>27476741</td>\n",
       "      <td>0.740333</td>\n",
       "      <td>0.778309</td>\n",
       "      <td>0.740333</td>\n",
       "      <td>0.624137</td>\n",
       "      <td>0.063016</td>\n",
       "      <td>0.842124</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>64</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>multi_output_finetune_DAVIS_cold_b00c0017</td>\n",
       "      <td>0.226926</td>\n",
       "      <td>0</td>\n",
       "      <td>27476741</td>\n",
       "      <td>1.837372</td>\n",
       "      <td>0.776653</td>\n",
       "      <td>1.837372</td>\n",
       "      <td>0.621787</td>\n",
       "      <td>-1.325425</td>\n",
       "      <td>1.318951</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>64</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.50</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>multi_output_finetune_DAVIS_cold_b00c0010</td>\n",
       "      <td>0.404908</td>\n",
       "      <td>0</td>\n",
       "      <td>27476741</td>\n",
       "      <td>2.046093</td>\n",
       "      <td>0.774466</td>\n",
       "      <td>2.046093</td>\n",
       "      <td>0.623576</td>\n",
       "      <td>-1.589605</td>\n",
       "      <td>1.421268</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>16</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.50</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>multi_output_finetune_DAVIS_cold_b00c0006</td>\n",
       "      <td>0.355166</td>\n",
       "      <td>0</td>\n",
       "      <td>27476741</td>\n",
       "      <td>1.530007</td>\n",
       "      <td>0.775428</td>\n",
       "      <td>1.530007</td>\n",
       "      <td>0.616358</td>\n",
       "      <td>-0.936411</td>\n",
       "      <td>1.221982</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>32</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.50</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>multi_output_finetune_DAVIS_cold_b00c0021</td>\n",
       "      <td>0.226926</td>\n",
       "      <td>0</td>\n",
       "      <td>27476741</td>\n",
       "      <td>0.851875</td>\n",
       "      <td>0.776771</td>\n",
       "      <td>0.851875</td>\n",
       "      <td>0.620067</td>\n",
       "      <td>-0.078155</td>\n",
       "      <td>0.902189</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>64</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>multi_output_finetune_DAVIS_cold_b00c0025</td>\n",
       "      <td>0.355166</td>\n",
       "      <td>0</td>\n",
       "      <td>27476741</td>\n",
       "      <td>0.687536</td>\n",
       "      <td>0.776248</td>\n",
       "      <td>0.687536</td>\n",
       "      <td>0.621337</td>\n",
       "      <td>0.129840</td>\n",
       "      <td>0.822881</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>32</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>multi_output_finetune_DAVIS_cold_b00c0013</td>\n",
       "      <td>0.355166</td>\n",
       "      <td>0</td>\n",
       "      <td>27476741</td>\n",
       "      <td>1.757008</td>\n",
       "      <td>0.774191</td>\n",
       "      <td>1.757008</td>\n",
       "      <td>0.621761</td>\n",
       "      <td>-1.223708</td>\n",
       "      <td>1.308868</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>32</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.50</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              experiment_name  best_val_loss  best_epoch  \\\n",
       "0   multi_output_finetune_DAVIS_cold_b00c0002       0.404908           0   \n",
       "1   multi_output_finetune_DAVIS_cold_b00c0008       0.226926           0   \n",
       "2   multi_output_finetune_DAVIS_cold_b00c0003       0.226926           0   \n",
       "3   multi_output_finetune_DAVIS_cold_b00c0026       0.404908           0   \n",
       "4   multi_output_finetune_DAVIS_cold_b00c0005       0.226926           0   \n",
       "5   multi_output_finetune_DAVIS_cold_b00c0024       0.404908           0   \n",
       "6   multi_output_finetune_DAVIS_cold_b00c0023       0.355166           0   \n",
       "7   multi_output_finetune_DAVIS_cold_b00c0007       0.404908           0   \n",
       "8   multi_output_finetune_DAVIS_cold_b00c0000       0.226926           0   \n",
       "9   multi_output_finetune_DAVIS_cold_b00c0012       0.404908           0   \n",
       "10  multi_output_finetune_DAVIS_cold_b00c0020       0.355166           0   \n",
       "11  multi_output_finetune_DAVIS_cold_b00c0016       0.404908           0   \n",
       "12  multi_output_finetune_DAVIS_cold_b00c0011       0.404908           0   \n",
       "13  multi_output_finetune_DAVIS_cold_b00c0009       0.355166           0   \n",
       "14  multi_output_finetune_DAVIS_cold_b00c0022       0.226926           0   \n",
       "15  multi_output_finetune_DAVIS_cold_b00c0004       0.404908           0   \n",
       "16  multi_output_finetune_DAVIS_cold_b00c0015       0.355166           0   \n",
       "17  multi_output_finetune_DAVIS_cold_b00c0018       0.226926           0   \n",
       "18  multi_output_finetune_DAVIS_cold_b00c0019       0.355166           0   \n",
       "19  multi_output_finetune_DAVIS_cold_b00c0001       0.355166           0   \n",
       "20  multi_output_finetune_DAVIS_cold_b00c0014       0.226926           0   \n",
       "21  multi_output_finetune_DAVIS_cold_b00c0017       0.226926           0   \n",
       "22  multi_output_finetune_DAVIS_cold_b00c0010       0.404908           0   \n",
       "23  multi_output_finetune_DAVIS_cold_b00c0006       0.355166           0   \n",
       "24  multi_output_finetune_DAVIS_cold_b00c0021       0.226926           0   \n",
       "25  multi_output_finetune_DAVIS_cold_b00c0025       0.355166           0   \n",
       "26  multi_output_finetune_DAVIS_cold_b00c0013       0.355166           0   \n",
       "\n",
       "    trainable_params  val/loss  val/Y_pKd_ci  val/Y_pKd_mse  \\\n",
       "0           27476741  0.724740      0.778565       0.724740   \n",
       "1           27476741  0.706371      0.777105       0.706371   \n",
       "2           27476741  2.054697      0.774795       2.054697   \n",
       "3           27476741  2.253255      0.775438       2.253255   \n",
       "4           27476741  0.673331      0.776668       0.673331   \n",
       "5           27476741  0.690506      0.776527       0.690506   \n",
       "6           27476741  1.837927      0.772699       1.837927   \n",
       "7           27476741  0.979110      0.778651       0.979110   \n",
       "8           27476741  0.950711      0.777043       0.950711   \n",
       "9           27476741  0.916460      0.776402       0.916460   \n",
       "10          27476741  0.726738      0.779338       0.726738   \n",
       "11          27476741  1.663292      0.775007       1.663292   \n",
       "12          27476741  0.751307      0.780759       0.751307   \n",
       "13          27476741  0.991794      0.779585       0.991794   \n",
       "14          27476741  1.295194      0.776756       1.295194   \n",
       "15          27476741  1.005264      0.781399       1.005264   \n",
       "16          27476741  0.955632      0.777232       0.955632   \n",
       "17          27476741  0.983933      0.777134       0.983933   \n",
       "18          27476741  0.884318      0.776187       0.884318   \n",
       "19          27476741  0.733412      0.777101       0.733412   \n",
       "20          27476741  0.740333      0.778309       0.740333   \n",
       "21          27476741  1.837372      0.776653       1.837372   \n",
       "22          27476741  2.046093      0.774466       2.046093   \n",
       "23          27476741  1.530007      0.775428       1.530007   \n",
       "24          27476741  0.851875      0.776771       0.851875   \n",
       "25          27476741  0.687536      0.776248       0.687536   \n",
       "26          27476741  1.757008      0.774191       1.757008   \n",
       "\n",
       "    val/Y_pKd_pearson  val/Y_pKd_r2  val/Y_pKd_rmse  ...  config.loss.weights  \\\n",
       "0            0.625569      0.082744        0.848325  ...              1_0_0_0   \n",
       "1            0.624257      0.105999        0.822966  ...              1_0_0_0   \n",
       "2            0.626279     -1.600477        1.394190  ...              1_0_0_0   \n",
       "3            0.626443     -1.851798        1.491265  ...              1_0_0_0   \n",
       "4            0.621355      0.147815        0.803889  ...              1_0_0_0   \n",
       "5            0.622077      0.126071        0.828231  ...              1_0_0_0   \n",
       "6            0.624967     -1.326121        1.338478  ...              1_0_0_0   \n",
       "7            0.626377     -0.239195        0.984877  ...              1_0_0_0   \n",
       "8            0.625307     -0.203244        0.952252  ...              1_0_0_0   \n",
       "9            0.621097     -0.159903        0.953062  ...              1_0_0_0   \n",
       "10           0.625715      0.080225        0.845641  ...              1_0_0_0   \n",
       "11           0.617334     -1.105120        1.281908  ...              1_0_0_0   \n",
       "12           0.627797      0.049120        0.863598  ...              1_0_0_0   \n",
       "13           0.628807     -0.255237        0.985835  ...              1_0_0_0   \n",
       "14           0.616853     -0.639230        1.109215  ...              1_0_0_0   \n",
       "15           0.629576     -0.272297        0.997858  ...              1_0_0_0   \n",
       "16           0.626144     -0.209469        0.967905  ...              1_0_0_0   \n",
       "17           0.626870     -0.245290        0.968498  ...              1_0_0_0   \n",
       "18           0.620627     -0.119213        0.931535  ...              1_0_0_0   \n",
       "19           0.623312      0.071778        0.849455  ...              1_0_0_0   \n",
       "20           0.624137      0.063016        0.842124  ...              1_0_0_0   \n",
       "21           0.621787     -1.325425        1.318951  ...              1_0_0_0   \n",
       "22           0.623576     -1.589605        1.421268  ...              1_0_0_0   \n",
       "23           0.616358     -0.936411        1.221982  ...              1_0_0_0   \n",
       "24           0.620067     -0.078155        0.902189  ...              1_0_0_0   \n",
       "25           0.621337      0.129840        0.822881  ...              1_0_0_0   \n",
       "26           0.621761     -1.223708        1.308868  ...              1_0_0_0   \n",
       "\n",
       "    config.data.batch_size     config.data.h5_path  config.data.drug_features  \\\n",
       "0                       16  data/input/dti.h5torch                  FP-Morgan   \n",
       "1                       64  data/input/dti.h5torch                  FP-Morgan   \n",
       "2                       64  data/input/dti.h5torch                  FP-Morgan   \n",
       "3                       16  data/input/dti.h5torch                  FP-Morgan   \n",
       "4                       64  data/input/dti.h5torch                  FP-Morgan   \n",
       "5                       16  data/input/dti.h5torch                  FP-Morgan   \n",
       "6                       32  data/input/dti.h5torch                  FP-Morgan   \n",
       "7                       16  data/input/dti.h5torch                  FP-Morgan   \n",
       "8                       64  data/input/dti.h5torch                  FP-Morgan   \n",
       "9                       16  data/input/dti.h5torch                  FP-Morgan   \n",
       "10                      32  data/input/dti.h5torch                  FP-Morgan   \n",
       "11                      16  data/input/dti.h5torch                  FP-Morgan   \n",
       "12                      16  data/input/dti.h5torch                  FP-Morgan   \n",
       "13                      32  data/input/dti.h5torch                  FP-Morgan   \n",
       "14                      64  data/input/dti.h5torch                  FP-Morgan   \n",
       "15                      16  data/input/dti.h5torch                  FP-Morgan   \n",
       "16                      32  data/input/dti.h5torch                  FP-Morgan   \n",
       "17                      64  data/input/dti.h5torch                  FP-Morgan   \n",
       "18                      32  data/input/dti.h5torch                  FP-Morgan   \n",
       "19                      32  data/input/dti.h5torch                  FP-Morgan   \n",
       "20                      64  data/input/dti.h5torch                  FP-Morgan   \n",
       "21                      64  data/input/dti.h5torch                  FP-Morgan   \n",
       "22                      16  data/input/dti.h5torch                  FP-Morgan   \n",
       "23                      32  data/input/dti.h5torch                  FP-Morgan   \n",
       "24                      64  data/input/dti.h5torch                  FP-Morgan   \n",
       "25                      32  data/input/dti.h5torch                  FP-Morgan   \n",
       "26                      32  data/input/dti.h5torch                  FP-Morgan   \n",
       "\n",
       "    config.data.target_features  config.model.embedding_dim  \\\n",
       "0                        FP-ESP                        1024   \n",
       "1                        FP-ESP                        1024   \n",
       "2                        FP-ESP                        1024   \n",
       "3                        FP-ESP                        1024   \n",
       "4                        FP-ESP                        1024   \n",
       "5                        FP-ESP                        1024   \n",
       "6                        FP-ESP                        1024   \n",
       "7                        FP-ESP                        1024   \n",
       "8                        FP-ESP                        1024   \n",
       "9                        FP-ESP                        1024   \n",
       "10                       FP-ESP                        1024   \n",
       "11                       FP-ESP                        1024   \n",
       "12                       FP-ESP                        1024   \n",
       "13                       FP-ESP                        1024   \n",
       "14                       FP-ESP                        1024   \n",
       "15                       FP-ESP                        1024   \n",
       "16                       FP-ESP                        1024   \n",
       "17                       FP-ESP                        1024   \n",
       "18                       FP-ESP                        1024   \n",
       "19                       FP-ESP                        1024   \n",
       "20                       FP-ESP                        1024   \n",
       "21                       FP-ESP                        1024   \n",
       "22                       FP-ESP                        1024   \n",
       "23                       FP-ESP                        1024   \n",
       "24                       FP-ESP                        1024   \n",
       "25                       FP-ESP                        1024   \n",
       "26                       FP-ESP                        1024   \n",
       "\n",
       "    config.model.hidden_dim  config.model.n_layers  config.model.dropout  \\\n",
       "0                       512                      3                  0.10   \n",
       "1                       512                      3                  0.10   \n",
       "2                       512                      3                  0.50   \n",
       "3                       512                      3                  0.50   \n",
       "4                       512                      3                  0.10   \n",
       "5                       512                      3                  0.10   \n",
       "6                       512                      3                  0.50   \n",
       "7                       512                      3                  0.25   \n",
       "8                       512                      3                  0.25   \n",
       "9                       512                      3                  0.25   \n",
       "10                      512                      3                  0.10   \n",
       "11                      512                      3                  0.50   \n",
       "12                      512                      3                  0.10   \n",
       "13                      512                      3                  0.25   \n",
       "14                      512                      3                  0.50   \n",
       "15                      512                      3                  0.25   \n",
       "16                      512                      3                  0.25   \n",
       "17                      512                      3                  0.25   \n",
       "18                      512                      3                  0.25   \n",
       "19                      512                      3                  0.10   \n",
       "20                      512                      3                  0.10   \n",
       "21                      512                      3                  0.50   \n",
       "22                      512                      3                  0.50   \n",
       "23                      512                      3                  0.50   \n",
       "24                      512                      3                  0.25   \n",
       "25                      512                      3                  0.10   \n",
       "26                      512                      3                  0.50   \n",
       "\n",
       "    config.model.encoder_type  \n",
       "0                 transformer  \n",
       "1                 transformer  \n",
       "2                 transformer  \n",
       "3                 transformer  \n",
       "4                 transformer  \n",
       "5                 transformer  \n",
       "6                 transformer  \n",
       "7                 transformer  \n",
       "8                 transformer  \n",
       "9                 transformer  \n",
       "10                transformer  \n",
       "11                transformer  \n",
       "12                transformer  \n",
       "13                transformer  \n",
       "14                transformer  \n",
       "15                transformer  \n",
       "16                transformer  \n",
       "17                transformer  \n",
       "18                transformer  \n",
       "19                transformer  \n",
       "20                transformer  \n",
       "21                transformer  \n",
       "22                transformer  \n",
       "23                transformer  \n",
       "24                transformer  \n",
       "25                transformer  \n",
       "26                transformer  \n",
       "\n",
       "[27 rows x 31 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limit distribution\n",
      "X: torch.Size([8])\n",
      "E: torch.Size([5])\n",
      "Number of nodes: tensor([27]) (sampled)\n",
      "Node mask: tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True]])\n",
      "Z_T.X.shape: torch.Size([1, 27, 8])\n",
      "Z_T.E.shape: torch.Size([1, 27, 27, 5])\n",
      "Successfully created molecule: <rdkit.Chem.rdchem.Mol object at 0x757c5cd5a2e0>\n",
      "Molecule SMILES: C.C.CC.cc1CC(C)(o(c)CC)=n234c(-n(c)n)-c(c-2O3)n-12Oc-2(c)(c)c-4\n"
     ]
    }
   ],
   "source": [
    "from mb_vae_dti.training.diffusion.utils import *\n",
    "import json\n",
    "import torch\n",
    "\n",
    "json_path = \"data/processed/molecular_statistics.json\"\n",
    "\n",
    "stats = json.load(open(json_path))\n",
    "\n",
    "dataset_name = \"drugs_cold\"\n",
    "\n",
    "visualization_tools = MolecularVisualization(stats[\"general\"][\"atom_types\"])\n",
    "nodes_dist = DistributionNodes(stats[\"datasets\"][dataset_name][\"node_count_distribution\"])\n",
    "limit_dist = PlaceHolder(\n",
    "    X=torch.tensor(stats[\"datasets\"][dataset_name][\"node_marginals\"]), \n",
    "    E=torch.tensor(stats[\"datasets\"][dataset_name][\"edge_marginals\"]), \n",
    "    y=torch.ones(1) / 1\n",
    ")\n",
    "\n",
    "print(f\"Limit distribution\\nX: {limit_dist.X.shape}\\nE: {limit_dist.E.shape}\")\n",
    "\n",
    "n_nodes = nodes_dist.sample_n(1, device=\"cpu\")\n",
    "print(f\"Number of nodes: {n_nodes} (sampled)\")\n",
    "\n",
    "arange = torch.arange(max(n_nodes), device=\"cpu\").unsqueeze(0).expand(1, -1)\n",
    "node_mask = arange < n_nodes.unsqueeze(1)\n",
    "\n",
    "print(f\"Node mask: {node_mask}\")\n",
    "\n",
    "z_T = sample_discrete_feature_noise(limit_dist=limit_dist, node_mask=node_mask)\n",
    "\n",
    "print(f\"Z_T.X.shape: {z_T.X.shape}\")\n",
    "print(f\"Z_T.E.shape: {z_T.E.shape}\")\n",
    "\n",
    "edge_types = torch.argmax(z_T.E, dim=-1)\n",
    "edge_types = edge_types# - 1\n",
    "node_types = torch.argmax(z_T.X, dim=-1)\n",
    "\n",
    "\n",
    "limit_mol = visualization_tools.mol_from_graphs(node_types[0], edge_types[0])\n",
    "\n",
    "print(f\"Successfully created molecule: {limit_mol}\")\n",
    "if limit_mol is not None:\n",
    "    print(f\"Molecule SMILES: {Chem.MolToSmiles(limit_mol)}\")\n",
    "else:\n",
    "    print(\"Failed to create valid molecule\") \n",
    "\n",
    "\n",
    "import rdkit.Chem as Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "Draw.MolToFile(limit_mol, \"limit_mol.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mb-vae-dti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
