{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Experiments were conducted using:\n",
    "- `mb_vae_dti/training/run.py`: command line interface for training\n",
    "- and the scripts in `scripts/training/` for running the experiments\n",
    "\n",
    "This notebook shows some plots and analysis of the unsupervised pretraining, general DTI training and benchmark fine-tuning results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resolve import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 13:56:29,796 - mb_vae_dti.validating.analysis - INFO - Successfully loaded 54 results with 10 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>best_val_loss</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>val_metrics</th>\n",
       "      <th>test_metrics</th>\n",
       "      <th>trainable_params</th>\n",
       "      <th>config</th>\n",
       "      <th>timing.total_training_time</th>\n",
       "      <th>timing.avg_time_per_epoch</th>\n",
       "      <th>timing.total_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>multi_output_train_cold_b03c0003</td>\n",
       "      <td>0.930683</td>\n",
       "      <td>23</td>\n",
       "      <td>{'val/loss_Y': 0.3950285017490387, 'val/loss_Y...</td>\n",
       "      <td>{'test/loss_Y': 0.41485193371772766, 'test/los...</td>\n",
       "      <td>44318469</td>\n",
       "      <td>{'training.learning_rate': 0.001, 'training.sc...</td>\n",
       "      <td>22617.284016</td>\n",
       "      <td>628.257889</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>multi_output_train_cold_b04c0004</td>\n",
       "      <td>0.949205</td>\n",
       "      <td>23</td>\n",
       "      <td>{'val/loss_Y': 0.4063224196434021, 'val/loss_Y...</td>\n",
       "      <td>{'test/loss_Y': 0.4226910173892975, 'test/loss...</td>\n",
       "      <td>44318469</td>\n",
       "      <td>{'training.learning_rate': 0.0005, 'training.s...</td>\n",
       "      <td>23325.871034</td>\n",
       "      <td>647.940862</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>multi_output_train_cold_b05c0006</td>\n",
       "      <td>0.976269</td>\n",
       "      <td>15</td>\n",
       "      <td>{'val/loss_Y': 0.39521554112434387, 'val/loss_...</td>\n",
       "      <td>{'test/loss_Y': 0.39312589168548584, 'test/los...</td>\n",
       "      <td>45114885</td>\n",
       "      <td>{'training.learning_rate': 0.001, 'training.sc...</td>\n",
       "      <td>19861.862970</td>\n",
       "      <td>709.352249</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>multi_output_train_cold_b04c0000</td>\n",
       "      <td>0.978312</td>\n",
       "      <td>30</td>\n",
       "      <td>{'val/loss_Y': 0.424538791179657, 'val/loss_Y_...</td>\n",
       "      <td>{'test/loss_Y': 0.4308117628097534, 'test/loss...</td>\n",
       "      <td>45114885</td>\n",
       "      <td>{'training.learning_rate': 0.0005, 'training.s...</td>\n",
       "      <td>32525.072075</td>\n",
       "      <td>756.397025</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>multi_output_train_cold_b04c0002</td>\n",
       "      <td>1.010602</td>\n",
       "      <td>23</td>\n",
       "      <td>{'val/loss_Y': 0.378013014793396, 'val/loss_Y_...</td>\n",
       "      <td>{'test/loss_Y': 0.3944063186645508, 'test/loss...</td>\n",
       "      <td>44318469</td>\n",
       "      <td>{'training.learning_rate': 0.0005, 'training.s...</td>\n",
       "      <td>23376.830587</td>\n",
       "      <td>649.356405</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>multi_output_train_cold_b03c0005</td>\n",
       "      <td>1.031901</td>\n",
       "      <td>18</td>\n",
       "      <td>{'val/loss_Y': 0.39519548416137695, 'val/loss_...</td>\n",
       "      <td>{'test/loss_Y': 0.39965787529945374, 'test/los...</td>\n",
       "      <td>44318469</td>\n",
       "      <td>{'training.learning_rate': 0.001, 'training.sc...</td>\n",
       "      <td>20574.612862</td>\n",
       "      <td>663.697189</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>multi_output_train_cold_b01c0000</td>\n",
       "      <td>1.055216</td>\n",
       "      <td>30</td>\n",
       "      <td>{'val/loss_Y': 0.413931667804718, 'val/loss_Y_...</td>\n",
       "      <td>{'test/loss_Y': 0.42732730507850647, 'test/los...</td>\n",
       "      <td>45114885</td>\n",
       "      <td>{'training.learning_rate': 0.0005, 'training.s...</td>\n",
       "      <td>32669.414825</td>\n",
       "      <td>759.753833</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>multi_output_train_cold_b01c0006</td>\n",
       "      <td>1.065606</td>\n",
       "      <td>33</td>\n",
       "      <td>{'val/loss_Y': 0.3943135738372803, 'val/loss_Y...</td>\n",
       "      <td>{'test/loss_Y': 0.4135196805000305, 'test/loss...</td>\n",
       "      <td>44318469</td>\n",
       "      <td>{'training.learning_rate': 0.001, 'training.sc...</td>\n",
       "      <td>15363.062677</td>\n",
       "      <td>333.979623</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>multi_output_train_cold_b01c0004</td>\n",
       "      <td>1.069636</td>\n",
       "      <td>14</td>\n",
       "      <td>{'val/loss_Y': 0.3764750063419342, 'val/loss_Y...</td>\n",
       "      <td>{'test/loss_Y': 0.3752148747444153, 'test/loss...</td>\n",
       "      <td>44318469</td>\n",
       "      <td>{'training.learning_rate': 0.0001, 'training.s...</td>\n",
       "      <td>17504.269518</td>\n",
       "      <td>648.306278</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>multi_output_train_cold_b03c0008</td>\n",
       "      <td>1.076028</td>\n",
       "      <td>30</td>\n",
       "      <td>{'val/loss_Y': 0.4246678650379181, 'val/loss_Y...</td>\n",
       "      <td>{'test/loss_Y': 0.4334804117679596, 'test/loss...</td>\n",
       "      <td>45114885</td>\n",
       "      <td>{'training.learning_rate': 0.0001, 'training.s...</td>\n",
       "      <td>31228.618726</td>\n",
       "      <td>726.246947</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>multi_output_train_cold_b00c0000</td>\n",
       "      <td>1.081371</td>\n",
       "      <td>15</td>\n",
       "      <td>{'val/loss_Y': 0.4083598256111145, 'val/loss_Y...</td>\n",
       "      <td>{'test/loss_Y': 0.41881778836250305, 'test/los...</td>\n",
       "      <td>45114885</td>\n",
       "      <td>{'training.learning_rate': 0.001, 'training.sc...</td>\n",
       "      <td>21080.117419</td>\n",
       "      <td>752.861336</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>multi_output_train_cold_b02c0007</td>\n",
       "      <td>1.096464</td>\n",
       "      <td>23</td>\n",
       "      <td>{'val/loss_Y': 0.4062763750553131, 'val/loss_Y...</td>\n",
       "      <td>{'test/loss_Y': 0.4257235527038574, 'test/loss...</td>\n",
       "      <td>45114885</td>\n",
       "      <td>{'training.learning_rate': 0.001, 'training.sc...</td>\n",
       "      <td>13834.861220</td>\n",
       "      <td>384.301701</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>multi_output_train_cold_b00c0004</td>\n",
       "      <td>1.114163</td>\n",
       "      <td>19</td>\n",
       "      <td>{'val/loss_Y': 0.4070042073726654, 'val/loss_Y...</td>\n",
       "      <td>{'test/loss_Y': 0.4167795181274414, 'test/loss...</td>\n",
       "      <td>44318469</td>\n",
       "      <td>{'training.learning_rate': 0.0005, 'training.s...</td>\n",
       "      <td>10629.671358</td>\n",
       "      <td>332.177230</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>multi_output_train_cold_b02c0004</td>\n",
       "      <td>1.117084</td>\n",
       "      <td>30</td>\n",
       "      <td>{'val/loss_Y': 0.4115474820137024, 'val/loss_Y...</td>\n",
       "      <td>{'test/loss_Y': 0.4308963119983673, 'test/loss...</td>\n",
       "      <td>45114885</td>\n",
       "      <td>{'training.learning_rate': 0.0005, 'training.s...</td>\n",
       "      <td>16629.988890</td>\n",
       "      <td>386.743928</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>multi_output_train_cold_b05c0008</td>\n",
       "      <td>1.129344</td>\n",
       "      <td>13</td>\n",
       "      <td>{'val/loss_Y': 0.4176485538482666, 'val/loss_Y...</td>\n",
       "      <td>{'test/loss_Y': 0.42678794264793396, 'test/los...</td>\n",
       "      <td>44318469</td>\n",
       "      <td>{'training.learning_rate': 0.001, 'training.sc...</td>\n",
       "      <td>16124.371674</td>\n",
       "      <td>620.168141</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>multi_output_train_cold_b04c0003</td>\n",
       "      <td>1.144719</td>\n",
       "      <td>21</td>\n",
       "      <td>{'val/loss_Y': 0.4017789959907532, 'val/loss_Y...</td>\n",
       "      <td>{'test/loss_Y': 0.41487035155296326, 'test/los...</td>\n",
       "      <td>44318469</td>\n",
       "      <td>{'training.learning_rate': 0.0005, 'training.s...</td>\n",
       "      <td>21304.736957</td>\n",
       "      <td>626.609911</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>multi_output_train_cold_b01c0005</td>\n",
       "      <td>1.187610</td>\n",
       "      <td>41</td>\n",
       "      <td>{'val/loss_Y': 0.4056745171546936, 'val/loss_Y...</td>\n",
       "      <td>{'test/loss_Y': 0.4252513647079468, 'test/loss...</td>\n",
       "      <td>44318469</td>\n",
       "      <td>{'training.learning_rate': 0.0005, 'training.s...</td>\n",
       "      <td>18843.889680</td>\n",
       "      <td>348.960920</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>multi_output_train_cold_b01c0002</td>\n",
       "      <td>1.237608</td>\n",
       "      <td>30</td>\n",
       "      <td>{'val/loss_Y': 0.4088606834411621, 'val/loss_Y...</td>\n",
       "      <td>{'test/loss_Y': 0.43614405393600464, 'test/los...</td>\n",
       "      <td>45114885</td>\n",
       "      <td>{'training.learning_rate': 0.001, 'training.sc...</td>\n",
       "      <td>8129.000924</td>\n",
       "      <td>189.046533</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>multi_output_train_cold_b00c0003</td>\n",
       "      <td>1.239267</td>\n",
       "      <td>40</td>\n",
       "      <td>{'val/loss_Y': 0.41664057970046997, 'val/loss_...</td>\n",
       "      <td>{'test/loss_Y': 0.43464556336402893, 'test/los...</td>\n",
       "      <td>44318469</td>\n",
       "      <td>{'training.learning_rate': 0.0001, 'training.s...</td>\n",
       "      <td>32571.171576</td>\n",
       "      <td>614.550407</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>multi_output_train_cold_b03c0000</td>\n",
       "      <td>1.241438</td>\n",
       "      <td>21</td>\n",
       "      <td>{'val/loss_Y': 0.39808449149131775, 'val/loss_...</td>\n",
       "      <td>{'test/loss_Y': 0.40857622027397156, 'test/los...</td>\n",
       "      <td>44318469</td>\n",
       "      <td>{'training.learning_rate': 0.0005, 'training.s...</td>\n",
       "      <td>5767.184505</td>\n",
       "      <td>169.623074</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>multi_output_train_cold_b03c0007</td>\n",
       "      <td>1.251317</td>\n",
       "      <td>20</td>\n",
       "      <td>{'val/loss_Y': 0.40508368611335754, 'val/loss_...</td>\n",
       "      <td>{'test/loss_Y': 0.41225433349609375, 'test/los...</td>\n",
       "      <td>44318469</td>\n",
       "      <td>{'training.learning_rate': 0.0001, 'training.s...</td>\n",
       "      <td>11051.477605</td>\n",
       "      <td>334.893261</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>multi_output_train_cold_b05c0000</td>\n",
       "      <td>1.258216</td>\n",
       "      <td>27</td>\n",
       "      <td>{'val/loss_Y': 0.40029454231262207, 'val/loss_...</td>\n",
       "      <td>{'test/loss_Y': 0.42049023509025574, 'test/los...</td>\n",
       "      <td>44318469</td>\n",
       "      <td>{'training.learning_rate': 0.001, 'training.sc...</td>\n",
       "      <td>6777.847938</td>\n",
       "      <td>169.446198</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>multi_output_train_cold_b04c0006</td>\n",
       "      <td>1.267220</td>\n",
       "      <td>36</td>\n",
       "      <td>{'val/loss_Y': 0.4451933801174164, 'val/loss_Y...</td>\n",
       "      <td>{'test/loss_Y': 0.46751198172569275, 'test/los...</td>\n",
       "      <td>45114885</td>\n",
       "      <td>{'training.learning_rate': 0.0005, 'training.s...</td>\n",
       "      <td>18888.353590</td>\n",
       "      <td>385.476604</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>multi_output_train_cold_b03c0002</td>\n",
       "      <td>1.267290</td>\n",
       "      <td>53</td>\n",
       "      <td>{'val/loss_Y': 0.4929122030735016, 'val/loss_Y...</td>\n",
       "      <td>{'test/loss_Y': 0.5149414539337158, 'test/loss...</td>\n",
       "      <td>45114885</td>\n",
       "      <td>{'training.learning_rate': 0.0001, 'training.s...</td>\n",
       "      <td>49072.858981</td>\n",
       "      <td>743.528166</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>multi_output_train_cold_b03c0006</td>\n",
       "      <td>1.296568</td>\n",
       "      <td>51</td>\n",
       "      <td>{'val/loss_Y': 0.5733474493026733, 'val/loss_Y...</td>\n",
       "      <td>{'test/loss_Y': 0.5725377798080444, 'test/loss...</td>\n",
       "      <td>44318469</td>\n",
       "      <td>{'training.learning_rate': 0.0001, 'training.s...</td>\n",
       "      <td>41377.117958</td>\n",
       "      <td>646.517468</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>multi_output_train_cold_b03c0004</td>\n",
       "      <td>1.308238</td>\n",
       "      <td>21</td>\n",
       "      <td>{'val/loss_Y': 0.4117869734764099, 'val/loss_Y...</td>\n",
       "      <td>{'test/loss_Y': 0.42292603850364685, 'test/los...</td>\n",
       "      <td>44318469</td>\n",
       "      <td>{'training.learning_rate': 0.001, 'training.sc...</td>\n",
       "      <td>11603.635191</td>\n",
       "      <td>341.283388</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>multi_output_train_cold_b05c0002</td>\n",
       "      <td>1.311608</td>\n",
       "      <td>16</td>\n",
       "      <td>{'val/loss_Y': 0.42028698325157166, 'val/loss_...</td>\n",
       "      <td>{'test/loss_Y': 0.4220663905143738, 'test/loss...</td>\n",
       "      <td>45114885</td>\n",
       "      <td>{'training.learning_rate': 0.001, 'training.sc...</td>\n",
       "      <td>10920.672887</td>\n",
       "      <td>376.574927</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>multi_output_train_cold_b05c0003</td>\n",
       "      <td>1.314904</td>\n",
       "      <td>24</td>\n",
       "      <td>{'val/loss_Y': 0.4721110761165619, 'val/loss_Y...</td>\n",
       "      <td>{'test/loss_Y': 0.47042787075042725, 'test/los...</td>\n",
       "      <td>45114885</td>\n",
       "      <td>{'training.learning_rate': 0.001, 'training.sc...</td>\n",
       "      <td>26603.976943</td>\n",
       "      <td>719.026404</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>multi_output_train_cold_b05c0001</td>\n",
       "      <td>1.321968</td>\n",
       "      <td>26</td>\n",
       "      <td>{'val/loss_Y': 0.4644339382648468, 'val/loss_Y...</td>\n",
       "      <td>{'test/loss_Y': 0.46149948239326477, 'test/los...</td>\n",
       "      <td>45114885</td>\n",
       "      <td>{'training.learning_rate': 0.0005, 'training.s...</td>\n",
       "      <td>27847.082932</td>\n",
       "      <td>714.027767</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>multi_output_train_cold_b05c0005</td>\n",
       "      <td>1.341277</td>\n",
       "      <td>33</td>\n",
       "      <td>{'val/loss_Y': 0.40225064754486084, 'val/loss_...</td>\n",
       "      <td>{'test/loss_Y': 0.414433091878891, 'test/loss_...</td>\n",
       "      <td>44318469</td>\n",
       "      <td>{'training.learning_rate': 0.001, 'training.sc...</td>\n",
       "      <td>7966.189146</td>\n",
       "      <td>173.178025</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>multi_output_train_cold_b02c0001</td>\n",
       "      <td>1.371673</td>\n",
       "      <td>37</td>\n",
       "      <td>{'val/loss_Y': 0.4087577760219574, 'val/loss_Y...</td>\n",
       "      <td>{'test/loss_Y': 0.4309678077697754, 'test/loss...</td>\n",
       "      <td>44318469</td>\n",
       "      <td>{'training.learning_rate': 0.0005, 'training.s...</td>\n",
       "      <td>16396.713042</td>\n",
       "      <td>327.934261</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>multi_output_train_cold_b04c0008</td>\n",
       "      <td>1.386737</td>\n",
       "      <td>19</td>\n",
       "      <td>{'val/loss_Y': 0.41526374220848083, 'val/loss_...</td>\n",
       "      <td>{'test/loss_Y': 0.4225159287452698, 'test/loss...</td>\n",
       "      <td>45114885</td>\n",
       "      <td>{'training.learning_rate': 0.0001, 'training.s...</td>\n",
       "      <td>12171.599904</td>\n",
       "      <td>380.362497</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>multi_output_train_cold_b04c0005</td>\n",
       "      <td>1.407444</td>\n",
       "      <td>29</td>\n",
       "      <td>{'val/loss_Y': 0.391365110874176, 'val/loss_Y_...</td>\n",
       "      <td>{'test/loss_Y': 0.40170350670814514, 'test/los...</td>\n",
       "      <td>44318469</td>\n",
       "      <td>{'training.learning_rate': 0.0005, 'training.s...</td>\n",
       "      <td>7277.128952</td>\n",
       "      <td>173.264975</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>multi_output_train_cold_b02c0000</td>\n",
       "      <td>1.435225</td>\n",
       "      <td>14</td>\n",
       "      <td>{'val/loss_Y': 0.3911615014076233, 'val/loss_Y...</td>\n",
       "      <td>{'test/loss_Y': 0.3949730098247528, 'test/loss...</td>\n",
       "      <td>44318469</td>\n",
       "      <td>{'training.learning_rate': 0.001, 'training.sc...</td>\n",
       "      <td>9479.408168</td>\n",
       "      <td>351.089191</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>multi_output_train_cold_b00c0007</td>\n",
       "      <td>1.457067</td>\n",
       "      <td>65</td>\n",
       "      <td>{'val/loss_Y': 0.5102746486663818, 'val/loss_Y...</td>\n",
       "      <td>{'test/loss_Y': 0.5385028719902039, 'test/loss...</td>\n",
       "      <td>45114885</td>\n",
       "      <td>{'training.learning_rate': 0.0001, 'training.s...</td>\n",
       "      <td>57283.497460</td>\n",
       "      <td>734.403814</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>multi_output_train_cold_b02c0002</td>\n",
       "      <td>1.470559</td>\n",
       "      <td>30</td>\n",
       "      <td>{'val/loss_Y': 0.4157561659812927, 'val/loss_Y...</td>\n",
       "      <td>{'test/loss_Y': 0.43083783984184265, 'test/los...</td>\n",
       "      <td>45114885</td>\n",
       "      <td>{'training.learning_rate': 0.0005, 'training.s...</td>\n",
       "      <td>8124.625961</td>\n",
       "      <td>188.944790</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>multi_output_train_cold_b00c0002</td>\n",
       "      <td>1.484322</td>\n",
       "      <td>41</td>\n",
       "      <td>{'val/loss_Y': 0.4438537657260895, 'val/loss_Y...</td>\n",
       "      <td>{'test/loss_Y': 0.4685438871383667, 'test/loss...</td>\n",
       "      <td>45114885</td>\n",
       "      <td>{'training.learning_rate': 0.0005, 'training.s...</td>\n",
       "      <td>20076.619832</td>\n",
       "      <td>371.789256</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>multi_output_train_cold_b02c0008</td>\n",
       "      <td>1.489573</td>\n",
       "      <td>16</td>\n",
       "      <td>{'val/loss_Y': 0.457327663898468, 'val/loss_Y_...</td>\n",
       "      <td>{'test/loss_Y': 0.45648637413978577, 'test/los...</td>\n",
       "      <td>45114885</td>\n",
       "      <td>{'training.learning_rate': 0.001, 'training.sc...</td>\n",
       "      <td>10969.623014</td>\n",
       "      <td>378.262863</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>multi_output_train_cold_b01c0001</td>\n",
       "      <td>1.494035</td>\n",
       "      <td>40</td>\n",
       "      <td>{'val/loss_Y': 0.5238146185874939, 'val/loss_Y...</td>\n",
       "      <td>{'test/loss_Y': 0.49922147393226624, 'test/los...</td>\n",
       "      <td>45114885</td>\n",
       "      <td>{'training.learning_rate': 0.0005, 'training.s...</td>\n",
       "      <td>10102.296760</td>\n",
       "      <td>190.609373</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>multi_output_train_cold_b02c0005</td>\n",
       "      <td>1.497590</td>\n",
       "      <td>29</td>\n",
       "      <td>{'val/loss_Y': 0.4564685523509979, 'val/loss_Y...</td>\n",
       "      <td>{'test/loss_Y': 0.4718436896800995, 'test/loss...</td>\n",
       "      <td>44318469</td>\n",
       "      <td>{'training.learning_rate': 0.0001, 'training.s...</td>\n",
       "      <td>7202.109980</td>\n",
       "      <td>171.478809</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>multi_output_train_cold_b02c0003</td>\n",
       "      <td>1.507923</td>\n",
       "      <td>68</td>\n",
       "      <td>{'val/loss_Y': 0.4661411941051483, 'val/loss_Y...</td>\n",
       "      <td>{'test/loss_Y': 0.48262035846710205, 'test/los...</td>\n",
       "      <td>44318469</td>\n",
       "      <td>{'training.learning_rate': 0.0001, 'training.s...</td>\n",
       "      <td>27212.293997</td>\n",
       "      <td>335.954247</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>multi_output_train_cold_b01c0007</td>\n",
       "      <td>1.591628</td>\n",
       "      <td>43</td>\n",
       "      <td>{'val/loss_Y': 0.41695380210876465, 'val/loss_...</td>\n",
       "      <td>{'test/loss_Y': 0.43593263626098633, 'test/los...</td>\n",
       "      <td>44318469</td>\n",
       "      <td>{'training.learning_rate': 0.0005, 'training.s...</td>\n",
       "      <td>9504.798722</td>\n",
       "      <td>169.728549</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>multi_output_train_cold_b00c0006</td>\n",
       "      <td>1.595809</td>\n",
       "      <td>30</td>\n",
       "      <td>{'val/loss_Y': 0.4164227247238159, 'val/loss_Y...</td>\n",
       "      <td>{'test/loss_Y': 0.4235130846500397, 'test/loss...</td>\n",
       "      <td>45114885</td>\n",
       "      <td>{'training.learning_rate': 0.0001, 'training.s...</td>\n",
       "      <td>8043.045555</td>\n",
       "      <td>187.047571</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>multi_output_train_cold_b02c0006</td>\n",
       "      <td>1.597283</td>\n",
       "      <td>36</td>\n",
       "      <td>{'val/loss_Y': 0.45246416330337524, 'val/loss_...</td>\n",
       "      <td>{'test/loss_Y': 0.46953344345092773, 'test/los...</td>\n",
       "      <td>45114885</td>\n",
       "      <td>{'training.learning_rate': 0.001, 'training.sc...</td>\n",
       "      <td>9298.151139</td>\n",
       "      <td>189.758187</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>multi_output_train_cold_b00c0005</td>\n",
       "      <td>1.641326</td>\n",
       "      <td>42</td>\n",
       "      <td>{'val/loss_Y': 0.43268972635269165, 'val/loss_...</td>\n",
       "      <td>{'test/loss_Y': 0.44949665665626526, 'test/los...</td>\n",
       "      <td>44318469</td>\n",
       "      <td>{'training.learning_rate': 0.001, 'training.sc...</td>\n",
       "      <td>9085.029913</td>\n",
       "      <td>165.182362</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>multi_output_train_cold_b03c0001</td>\n",
       "      <td>1.725885</td>\n",
       "      <td>73</td>\n",
       "      <td>{'val/loss_Y': 0.5933445692062378, 'val/loss_Y...</td>\n",
       "      <td>{'test/loss_Y': 0.6147800087928772, 'test/loss...</td>\n",
       "      <td>45114885</td>\n",
       "      <td>{'training.learning_rate': 0.0001, 'training.s...</td>\n",
       "      <td>32119.772657</td>\n",
       "      <td>373.485729</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>multi_output_train_cold_b05c0004</td>\n",
       "      <td>1.737471</td>\n",
       "      <td>36</td>\n",
       "      <td>{'val/loss_Y': 0.45793816447257996, 'val/loss_...</td>\n",
       "      <td>{'test/loss_Y': 0.4931383430957794, 'test/loss...</td>\n",
       "      <td>45114885</td>\n",
       "      <td>{'training.learning_rate': 0.0005, 'training.s...</td>\n",
       "      <td>9429.000158</td>\n",
       "      <td>192.428575</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>multi_output_train_cold_b04c0007</td>\n",
       "      <td>1.766541</td>\n",
       "      <td>52</td>\n",
       "      <td>{'val/loss_Y': 0.5638989210128784, 'val/loss_Y...</td>\n",
       "      <td>{'test/loss_Y': 0.5805854797363281, 'test/loss...</td>\n",
       "      <td>44318469</td>\n",
       "      <td>{'training.learning_rate': 0.0001, 'training.s...</td>\n",
       "      <td>21693.713682</td>\n",
       "      <td>333.749441</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>multi_output_train_cold_b04c0001</td>\n",
       "      <td>1.795424</td>\n",
       "      <td>51</td>\n",
       "      <td>{'val/loss_Y': 0.490705668926239, 'val/loss_Y_...</td>\n",
       "      <td>{'test/loss_Y': 0.5006024837493896, 'test/loss...</td>\n",
       "      <td>45114885</td>\n",
       "      <td>{'training.learning_rate': 0.0001, 'training.s...</td>\n",
       "      <td>24006.384722</td>\n",
       "      <td>375.099761</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multi_output_train_cold_b01c0003</td>\n",
       "      <td>1.856010</td>\n",
       "      <td>26</td>\n",
       "      <td>{'val/loss_Y': 0.4669041931629181, 'val/loss_Y...</td>\n",
       "      <td>{'test/loss_Y': 0.4780596196651459, 'test/loss...</td>\n",
       "      <td>45114885</td>\n",
       "      <td>{'training.learning_rate': 0.001, 'training.sc...</td>\n",
       "      <td>7381.215617</td>\n",
       "      <td>189.261939</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>multi_output_train_cold_b00c0001</td>\n",
       "      <td>1.922763</td>\n",
       "      <td>76</td>\n",
       "      <td>{'val/loss_Y': 0.4672600030899048, 'val/loss_Y...</td>\n",
       "      <td>{'test/loss_Y': 0.47893673181533813, 'test/los...</td>\n",
       "      <td>44318469</td>\n",
       "      <td>{'training.learning_rate': 0.0001, 'training.s...</td>\n",
       "      <td>15482.976768</td>\n",
       "      <td>173.966031</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>multi_output_train_cold_b01c0008</td>\n",
       "      <td>2.166975</td>\n",
       "      <td>66</td>\n",
       "      <td>{'val/loss_Y': 0.477647066116333, 'val/loss_Y_...</td>\n",
       "      <td>{'test/loss_Y': 0.5019679069519043, 'test/loss...</td>\n",
       "      <td>45114885</td>\n",
       "      <td>{'training.learning_rate': 0.0001, 'training.s...</td>\n",
       "      <td>15127.764248</td>\n",
       "      <td>191.490687</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>multi_output_train_cold_b00c0008</td>\n",
       "      <td>2.489153</td>\n",
       "      <td>68</td>\n",
       "      <td>{'val/loss_Y': 0.554476261138916, 'val/loss_Y_...</td>\n",
       "      <td>{'test/loss_Y': 0.5868475437164307, 'test/loss...</td>\n",
       "      <td>45114885</td>\n",
       "      <td>{'training.learning_rate': 0.0001, 'training.s...</td>\n",
       "      <td>14781.643331</td>\n",
       "      <td>182.489424</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>multi_output_train_cold_b05c0007</td>\n",
       "      <td>2.660870</td>\n",
       "      <td>62</td>\n",
       "      <td>{'val/loss_Y': 0.6374551057815552, 'val/loss_Y...</td>\n",
       "      <td>{'test/loss_Y': 0.652269184589386, 'test/loss_...</td>\n",
       "      <td>44318469</td>\n",
       "      <td>{'training.learning_rate': 0.0001, 'training.s...</td>\n",
       "      <td>12344.690563</td>\n",
       "      <td>164.595874</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     experiment_name  best_val_loss  best_epoch  \\\n",
       "16  multi_output_train_cold_b03c0003       0.930683          23   \n",
       "40  multi_output_train_cold_b04c0004       0.949205          23   \n",
       "25  multi_output_train_cold_b05c0006       0.976269          15   \n",
       "39  multi_output_train_cold_b04c0000       0.978312          30   \n",
       "19  multi_output_train_cold_b04c0002       1.010602          23   \n",
       "30  multi_output_train_cold_b03c0005       1.031901          18   \n",
       "13  multi_output_train_cold_b01c0000       1.055216          30   \n",
       "22  multi_output_train_cold_b01c0006       1.065606          33   \n",
       "12  multi_output_train_cold_b01c0004       1.069636          14   \n",
       "21  multi_output_train_cold_b03c0008       1.076028          30   \n",
       "49  multi_output_train_cold_b00c0000       1.081371          15   \n",
       "34  multi_output_train_cold_b02c0007       1.096464          23   \n",
       "10  multi_output_train_cold_b00c0004       1.114163          19   \n",
       "50  multi_output_train_cold_b02c0004       1.117084          30   \n",
       "15  multi_output_train_cold_b05c0008       1.129344          13   \n",
       "6   multi_output_train_cold_b04c0003       1.144719          21   \n",
       "51  multi_output_train_cold_b01c0005       1.187610          41   \n",
       "45  multi_output_train_cold_b01c0002       1.237608          30   \n",
       "52  multi_output_train_cold_b00c0003       1.239267          40   \n",
       "7   multi_output_train_cold_b03c0000       1.241438          21   \n",
       "48  multi_output_train_cold_b03c0007       1.251317          20   \n",
       "1   multi_output_train_cold_b05c0000       1.258216          27   \n",
       "28  multi_output_train_cold_b04c0006       1.267220          36   \n",
       "37  multi_output_train_cold_b03c0002       1.267290          53   \n",
       "9   multi_output_train_cold_b03c0006       1.296568          51   \n",
       "42  multi_output_train_cold_b03c0004       1.308238          21   \n",
       "32  multi_output_train_cold_b05c0002       1.311608          16   \n",
       "33  multi_output_train_cold_b05c0003       1.314904          24   \n",
       "26  multi_output_train_cold_b05c0001       1.321968          26   \n",
       "41  multi_output_train_cold_b05c0005       1.341277          33   \n",
       "24  multi_output_train_cold_b02c0001       1.371673          37   \n",
       "20  multi_output_train_cold_b04c0008       1.386737          19   \n",
       "47  multi_output_train_cold_b04c0005       1.407444          29   \n",
       "17  multi_output_train_cold_b02c0000       1.435225          14   \n",
       "27  multi_output_train_cold_b00c0007       1.457067          65   \n",
       "31  multi_output_train_cold_b02c0002       1.470559          30   \n",
       "35  multi_output_train_cold_b00c0002       1.484322          41   \n",
       "3   multi_output_train_cold_b02c0008       1.489573          16   \n",
       "23  multi_output_train_cold_b01c0001       1.494035          40   \n",
       "5   multi_output_train_cold_b02c0005       1.497590          29   \n",
       "38  multi_output_train_cold_b02c0003       1.507923          68   \n",
       "36  multi_output_train_cold_b01c0007       1.591628          43   \n",
       "46  multi_output_train_cold_b00c0006       1.595809          30   \n",
       "43  multi_output_train_cold_b02c0006       1.597283          36   \n",
       "2   multi_output_train_cold_b00c0005       1.641326          42   \n",
       "29  multi_output_train_cold_b03c0001       1.725885          73   \n",
       "44  multi_output_train_cold_b05c0004       1.737471          36   \n",
       "18  multi_output_train_cold_b04c0007       1.766541          52   \n",
       "4   multi_output_train_cold_b04c0001       1.795424          51   \n",
       "0   multi_output_train_cold_b01c0003       1.856010          26   \n",
       "8   multi_output_train_cold_b00c0001       1.922763          76   \n",
       "11  multi_output_train_cold_b01c0008       2.166975          66   \n",
       "14  multi_output_train_cold_b00c0008       2.489153          68   \n",
       "53  multi_output_train_cold_b05c0007       2.660870          62   \n",
       "\n",
       "                                          val_metrics  \\\n",
       "16  {'val/loss_Y': 0.3950285017490387, 'val/loss_Y...   \n",
       "40  {'val/loss_Y': 0.4063224196434021, 'val/loss_Y...   \n",
       "25  {'val/loss_Y': 0.39521554112434387, 'val/loss_...   \n",
       "39  {'val/loss_Y': 0.424538791179657, 'val/loss_Y_...   \n",
       "19  {'val/loss_Y': 0.378013014793396, 'val/loss_Y_...   \n",
       "30  {'val/loss_Y': 0.39519548416137695, 'val/loss_...   \n",
       "13  {'val/loss_Y': 0.413931667804718, 'val/loss_Y_...   \n",
       "22  {'val/loss_Y': 0.3943135738372803, 'val/loss_Y...   \n",
       "12  {'val/loss_Y': 0.3764750063419342, 'val/loss_Y...   \n",
       "21  {'val/loss_Y': 0.4246678650379181, 'val/loss_Y...   \n",
       "49  {'val/loss_Y': 0.4083598256111145, 'val/loss_Y...   \n",
       "34  {'val/loss_Y': 0.4062763750553131, 'val/loss_Y...   \n",
       "10  {'val/loss_Y': 0.4070042073726654, 'val/loss_Y...   \n",
       "50  {'val/loss_Y': 0.4115474820137024, 'val/loss_Y...   \n",
       "15  {'val/loss_Y': 0.4176485538482666, 'val/loss_Y...   \n",
       "6   {'val/loss_Y': 0.4017789959907532, 'val/loss_Y...   \n",
       "51  {'val/loss_Y': 0.4056745171546936, 'val/loss_Y...   \n",
       "45  {'val/loss_Y': 0.4088606834411621, 'val/loss_Y...   \n",
       "52  {'val/loss_Y': 0.41664057970046997, 'val/loss_...   \n",
       "7   {'val/loss_Y': 0.39808449149131775, 'val/loss_...   \n",
       "48  {'val/loss_Y': 0.40508368611335754, 'val/loss_...   \n",
       "1   {'val/loss_Y': 0.40029454231262207, 'val/loss_...   \n",
       "28  {'val/loss_Y': 0.4451933801174164, 'val/loss_Y...   \n",
       "37  {'val/loss_Y': 0.4929122030735016, 'val/loss_Y...   \n",
       "9   {'val/loss_Y': 0.5733474493026733, 'val/loss_Y...   \n",
       "42  {'val/loss_Y': 0.4117869734764099, 'val/loss_Y...   \n",
       "32  {'val/loss_Y': 0.42028698325157166, 'val/loss_...   \n",
       "33  {'val/loss_Y': 0.4721110761165619, 'val/loss_Y...   \n",
       "26  {'val/loss_Y': 0.4644339382648468, 'val/loss_Y...   \n",
       "41  {'val/loss_Y': 0.40225064754486084, 'val/loss_...   \n",
       "24  {'val/loss_Y': 0.4087577760219574, 'val/loss_Y...   \n",
       "20  {'val/loss_Y': 0.41526374220848083, 'val/loss_...   \n",
       "47  {'val/loss_Y': 0.391365110874176, 'val/loss_Y_...   \n",
       "17  {'val/loss_Y': 0.3911615014076233, 'val/loss_Y...   \n",
       "27  {'val/loss_Y': 0.5102746486663818, 'val/loss_Y...   \n",
       "31  {'val/loss_Y': 0.4157561659812927, 'val/loss_Y...   \n",
       "35  {'val/loss_Y': 0.4438537657260895, 'val/loss_Y...   \n",
       "3   {'val/loss_Y': 0.457327663898468, 'val/loss_Y_...   \n",
       "23  {'val/loss_Y': 0.5238146185874939, 'val/loss_Y...   \n",
       "5   {'val/loss_Y': 0.4564685523509979, 'val/loss_Y...   \n",
       "38  {'val/loss_Y': 0.4661411941051483, 'val/loss_Y...   \n",
       "36  {'val/loss_Y': 0.41695380210876465, 'val/loss_...   \n",
       "46  {'val/loss_Y': 0.4164227247238159, 'val/loss_Y...   \n",
       "43  {'val/loss_Y': 0.45246416330337524, 'val/loss_...   \n",
       "2   {'val/loss_Y': 0.43268972635269165, 'val/loss_...   \n",
       "29  {'val/loss_Y': 0.5933445692062378, 'val/loss_Y...   \n",
       "44  {'val/loss_Y': 0.45793816447257996, 'val/loss_...   \n",
       "18  {'val/loss_Y': 0.5638989210128784, 'val/loss_Y...   \n",
       "4   {'val/loss_Y': 0.490705668926239, 'val/loss_Y_...   \n",
       "0   {'val/loss_Y': 0.4669041931629181, 'val/loss_Y...   \n",
       "8   {'val/loss_Y': 0.4672600030899048, 'val/loss_Y...   \n",
       "11  {'val/loss_Y': 0.477647066116333, 'val/loss_Y_...   \n",
       "14  {'val/loss_Y': 0.554476261138916, 'val/loss_Y_...   \n",
       "53  {'val/loss_Y': 0.6374551057815552, 'val/loss_Y...   \n",
       "\n",
       "                                         test_metrics  trainable_params  \\\n",
       "16  {'test/loss_Y': 0.41485193371772766, 'test/los...          44318469   \n",
       "40  {'test/loss_Y': 0.4226910173892975, 'test/loss...          44318469   \n",
       "25  {'test/loss_Y': 0.39312589168548584, 'test/los...          45114885   \n",
       "39  {'test/loss_Y': 0.4308117628097534, 'test/loss...          45114885   \n",
       "19  {'test/loss_Y': 0.3944063186645508, 'test/loss...          44318469   \n",
       "30  {'test/loss_Y': 0.39965787529945374, 'test/los...          44318469   \n",
       "13  {'test/loss_Y': 0.42732730507850647, 'test/los...          45114885   \n",
       "22  {'test/loss_Y': 0.4135196805000305, 'test/loss...          44318469   \n",
       "12  {'test/loss_Y': 0.3752148747444153, 'test/loss...          44318469   \n",
       "21  {'test/loss_Y': 0.4334804117679596, 'test/loss...          45114885   \n",
       "49  {'test/loss_Y': 0.41881778836250305, 'test/los...          45114885   \n",
       "34  {'test/loss_Y': 0.4257235527038574, 'test/loss...          45114885   \n",
       "10  {'test/loss_Y': 0.4167795181274414, 'test/loss...          44318469   \n",
       "50  {'test/loss_Y': 0.4308963119983673, 'test/loss...          45114885   \n",
       "15  {'test/loss_Y': 0.42678794264793396, 'test/los...          44318469   \n",
       "6   {'test/loss_Y': 0.41487035155296326, 'test/los...          44318469   \n",
       "51  {'test/loss_Y': 0.4252513647079468, 'test/loss...          44318469   \n",
       "45  {'test/loss_Y': 0.43614405393600464, 'test/los...          45114885   \n",
       "52  {'test/loss_Y': 0.43464556336402893, 'test/los...          44318469   \n",
       "7   {'test/loss_Y': 0.40857622027397156, 'test/los...          44318469   \n",
       "48  {'test/loss_Y': 0.41225433349609375, 'test/los...          44318469   \n",
       "1   {'test/loss_Y': 0.42049023509025574, 'test/los...          44318469   \n",
       "28  {'test/loss_Y': 0.46751198172569275, 'test/los...          45114885   \n",
       "37  {'test/loss_Y': 0.5149414539337158, 'test/loss...          45114885   \n",
       "9   {'test/loss_Y': 0.5725377798080444, 'test/loss...          44318469   \n",
       "42  {'test/loss_Y': 0.42292603850364685, 'test/los...          44318469   \n",
       "32  {'test/loss_Y': 0.4220663905143738, 'test/loss...          45114885   \n",
       "33  {'test/loss_Y': 0.47042787075042725, 'test/los...          45114885   \n",
       "26  {'test/loss_Y': 0.46149948239326477, 'test/los...          45114885   \n",
       "41  {'test/loss_Y': 0.414433091878891, 'test/loss_...          44318469   \n",
       "24  {'test/loss_Y': 0.4309678077697754, 'test/loss...          44318469   \n",
       "20  {'test/loss_Y': 0.4225159287452698, 'test/loss...          45114885   \n",
       "47  {'test/loss_Y': 0.40170350670814514, 'test/los...          44318469   \n",
       "17  {'test/loss_Y': 0.3949730098247528, 'test/loss...          44318469   \n",
       "27  {'test/loss_Y': 0.5385028719902039, 'test/loss...          45114885   \n",
       "31  {'test/loss_Y': 0.43083783984184265, 'test/los...          45114885   \n",
       "35  {'test/loss_Y': 0.4685438871383667, 'test/loss...          45114885   \n",
       "3   {'test/loss_Y': 0.45648637413978577, 'test/los...          45114885   \n",
       "23  {'test/loss_Y': 0.49922147393226624, 'test/los...          45114885   \n",
       "5   {'test/loss_Y': 0.4718436896800995, 'test/loss...          44318469   \n",
       "38  {'test/loss_Y': 0.48262035846710205, 'test/los...          44318469   \n",
       "36  {'test/loss_Y': 0.43593263626098633, 'test/los...          44318469   \n",
       "46  {'test/loss_Y': 0.4235130846500397, 'test/loss...          45114885   \n",
       "43  {'test/loss_Y': 0.46953344345092773, 'test/los...          45114885   \n",
       "2   {'test/loss_Y': 0.44949665665626526, 'test/los...          44318469   \n",
       "29  {'test/loss_Y': 0.6147800087928772, 'test/loss...          45114885   \n",
       "44  {'test/loss_Y': 0.4931383430957794, 'test/loss...          45114885   \n",
       "18  {'test/loss_Y': 0.5805854797363281, 'test/loss...          44318469   \n",
       "4   {'test/loss_Y': 0.5006024837493896, 'test/loss...          45114885   \n",
       "0   {'test/loss_Y': 0.4780596196651459, 'test/loss...          45114885   \n",
       "8   {'test/loss_Y': 0.47893673181533813, 'test/los...          44318469   \n",
       "11  {'test/loss_Y': 0.5019679069519043, 'test/loss...          45114885   \n",
       "14  {'test/loss_Y': 0.5868475437164307, 'test/loss...          45114885   \n",
       "53  {'test/loss_Y': 0.652269184589386, 'test/loss_...          44318469   \n",
       "\n",
       "                                               config  \\\n",
       "16  {'training.learning_rate': 0.001, 'training.sc...   \n",
       "40  {'training.learning_rate': 0.0005, 'training.s...   \n",
       "25  {'training.learning_rate': 0.001, 'training.sc...   \n",
       "39  {'training.learning_rate': 0.0005, 'training.s...   \n",
       "19  {'training.learning_rate': 0.0005, 'training.s...   \n",
       "30  {'training.learning_rate': 0.001, 'training.sc...   \n",
       "13  {'training.learning_rate': 0.0005, 'training.s...   \n",
       "22  {'training.learning_rate': 0.001, 'training.sc...   \n",
       "12  {'training.learning_rate': 0.0001, 'training.s...   \n",
       "21  {'training.learning_rate': 0.0001, 'training.s...   \n",
       "49  {'training.learning_rate': 0.001, 'training.sc...   \n",
       "34  {'training.learning_rate': 0.001, 'training.sc...   \n",
       "10  {'training.learning_rate': 0.0005, 'training.s...   \n",
       "50  {'training.learning_rate': 0.0005, 'training.s...   \n",
       "15  {'training.learning_rate': 0.001, 'training.sc...   \n",
       "6   {'training.learning_rate': 0.0005, 'training.s...   \n",
       "51  {'training.learning_rate': 0.0005, 'training.s...   \n",
       "45  {'training.learning_rate': 0.001, 'training.sc...   \n",
       "52  {'training.learning_rate': 0.0001, 'training.s...   \n",
       "7   {'training.learning_rate': 0.0005, 'training.s...   \n",
       "48  {'training.learning_rate': 0.0001, 'training.s...   \n",
       "1   {'training.learning_rate': 0.001, 'training.sc...   \n",
       "28  {'training.learning_rate': 0.0005, 'training.s...   \n",
       "37  {'training.learning_rate': 0.0001, 'training.s...   \n",
       "9   {'training.learning_rate': 0.0001, 'training.s...   \n",
       "42  {'training.learning_rate': 0.001, 'training.sc...   \n",
       "32  {'training.learning_rate': 0.001, 'training.sc...   \n",
       "33  {'training.learning_rate': 0.001, 'training.sc...   \n",
       "26  {'training.learning_rate': 0.0005, 'training.s...   \n",
       "41  {'training.learning_rate': 0.001, 'training.sc...   \n",
       "24  {'training.learning_rate': 0.0005, 'training.s...   \n",
       "20  {'training.learning_rate': 0.0001, 'training.s...   \n",
       "47  {'training.learning_rate': 0.0005, 'training.s...   \n",
       "17  {'training.learning_rate': 0.001, 'training.sc...   \n",
       "27  {'training.learning_rate': 0.0001, 'training.s...   \n",
       "31  {'training.learning_rate': 0.0005, 'training.s...   \n",
       "35  {'training.learning_rate': 0.0005, 'training.s...   \n",
       "3   {'training.learning_rate': 0.001, 'training.sc...   \n",
       "23  {'training.learning_rate': 0.0005, 'training.s...   \n",
       "5   {'training.learning_rate': 0.0001, 'training.s...   \n",
       "38  {'training.learning_rate': 0.0001, 'training.s...   \n",
       "36  {'training.learning_rate': 0.0005, 'training.s...   \n",
       "46  {'training.learning_rate': 0.0001, 'training.s...   \n",
       "43  {'training.learning_rate': 0.001, 'training.sc...   \n",
       "2   {'training.learning_rate': 0.001, 'training.sc...   \n",
       "29  {'training.learning_rate': 0.0001, 'training.s...   \n",
       "44  {'training.learning_rate': 0.0005, 'training.s...   \n",
       "18  {'training.learning_rate': 0.0001, 'training.s...   \n",
       "4   {'training.learning_rate': 0.0001, 'training.s...   \n",
       "0   {'training.learning_rate': 0.001, 'training.sc...   \n",
       "8   {'training.learning_rate': 0.0001, 'training.s...   \n",
       "11  {'training.learning_rate': 0.0001, 'training.s...   \n",
       "14  {'training.learning_rate': 0.0001, 'training.s...   \n",
       "53  {'training.learning_rate': 0.0001, 'training.s...   \n",
       "\n",
       "    timing.total_training_time  timing.avg_time_per_epoch  timing.total_epochs  \n",
       "16                22617.284016                 628.257889                   36  \n",
       "40                23325.871034                 647.940862                   36  \n",
       "25                19861.862970                 709.352249                   28  \n",
       "39                32525.072075                 756.397025                   43  \n",
       "19                23376.830587                 649.356405                   36  \n",
       "30                20574.612862                 663.697189                   31  \n",
       "13                32669.414825                 759.753833                   43  \n",
       "22                15363.062677                 333.979623                   46  \n",
       "12                17504.269518                 648.306278                   27  \n",
       "21                31228.618726                 726.246947                   43  \n",
       "49                21080.117419                 752.861336                   28  \n",
       "34                13834.861220                 384.301701                   36  \n",
       "10                10629.671358                 332.177230                   32  \n",
       "50                16629.988890                 386.743928                   43  \n",
       "15                16124.371674                 620.168141                   26  \n",
       "6                 21304.736957                 626.609911                   34  \n",
       "51                18843.889680                 348.960920                   54  \n",
       "45                 8129.000924                 189.046533                   43  \n",
       "52                32571.171576                 614.550407                   53  \n",
       "7                  5767.184505                 169.623074                   34  \n",
       "48                11051.477605                 334.893261                   33  \n",
       "1                  6777.847938                 169.446198                   40  \n",
       "28                18888.353590                 385.476604                   49  \n",
       "37                49072.858981                 743.528166                   66  \n",
       "9                 41377.117958                 646.517468                   64  \n",
       "42                11603.635191                 341.283388                   34  \n",
       "32                10920.672887                 376.574927                   29  \n",
       "33                26603.976943                 719.026404                   37  \n",
       "26                27847.082932                 714.027767                   39  \n",
       "41                 7966.189146                 173.178025                   46  \n",
       "24                16396.713042                 327.934261                   50  \n",
       "20                12171.599904                 380.362497                   32  \n",
       "47                 7277.128952                 173.264975                   42  \n",
       "17                 9479.408168                 351.089191                   27  \n",
       "27                57283.497460                 734.403814                   78  \n",
       "31                 8124.625961                 188.944790                   43  \n",
       "35                20076.619832                 371.789256                   54  \n",
       "3                 10969.623014                 378.262863                   29  \n",
       "23                10102.296760                 190.609373                   53  \n",
       "5                  7202.109980                 171.478809                   42  \n",
       "38                27212.293997                 335.954247                   81  \n",
       "36                 9504.798722                 169.728549                   56  \n",
       "46                 8043.045555                 187.047571                   43  \n",
       "43                 9298.151139                 189.758187                   49  \n",
       "2                  9085.029913                 165.182362                   55  \n",
       "29                32119.772657                 373.485729                   86  \n",
       "44                 9429.000158                 192.428575                   49  \n",
       "18                21693.713682                 333.749441                   65  \n",
       "4                 24006.384722                 375.099761                   64  \n",
       "0                  7381.215617                 189.261939                   39  \n",
       "8                 15482.976768                 173.966031                   89  \n",
       "11                15127.764248                 191.490687                   79  \n",
       "14                14781.643331                 182.489424                   81  \n",
       "53                12344.690563                 164.595874                   75  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mb_vae_dti.validating.analysis import *\n",
    "\n",
    "df = load_gridsearch_results(\"notebooks/results/mo_cold/\")\n",
    "\n",
    "if \"metadata.data.provenance_cols\" in df.columns:\n",
    "    df[\"metadata.data.provenance_cols\"] = df[\"metadata.data.provenance_cols\"].apply(lambda x: x[0])\n",
    "if \"metadata.data.drug_features\" in df.columns:\n",
    "    df = df.drop(columns=[\"metadata.data.drug_features\", \"metadata.data.target_features\"])\n",
    "\n",
    "df.sort_values(by=\"best_val_loss\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-27 19:35:42,354 - mb_vae_dti.validating.analysis - INFO - Found 8 varying attributes: ['metadata.training.learning_rate', 'metadata.data.batch_size', 'metadata.logging.experiment_name', 'metadata.model.encoder_kwargs.hidden_dim', 'metadata.model.encoder_kwargs.n_layers', 'metadata.model.embedding_dim', 'metadata.model.encoder_type', 'metadata.model.aggregator_type']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['metadata.training.learning_rate',\n",
       " 'metadata.data.batch_size',\n",
       " 'metadata.model.encoder_kwargs.hidden_dim',\n",
       " 'metadata.model.encoder_kwargs.n_layers',\n",
       " 'metadata.model.embedding_dim',\n",
       " 'metadata.model.encoder_type',\n",
       " 'metadata.model.aggregator_type',\n",
       " 'best_val_loss',\n",
       " 'best_epoch',\n",
       " 'trainable_params',\n",
       " 'timing.total_training_time']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varying_attrs = get_varying_attributes(df)\n",
    "varying_attrs.remove('metadata.logging.experiment_name')\n",
    "varying_attrs.extend([\"best_val_loss\", 'best_epoch', 'trainable_params', \"timing.total_training_time\"])\n",
    "varying_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time: 7.57 hours\n",
      "Average trainable params: 10.1M\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>n_layers</th>\n",
       "      <th>embedding_dim</th>\n",
       "      <th>encoder_type</th>\n",
       "      <th>aggregator_type</th>\n",
       "      <th>best_val_loss</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>trainable_params</th>\n",
       "      <th>total_training_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>resnet</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.154958</td>\n",
       "      <td>85</td>\n",
       "      <td>10555136</td>\n",
       "      <td>7962.247344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>32</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>resnet</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.155305</td>\n",
       "      <td>83</td>\n",
       "      <td>16484864</td>\n",
       "      <td>2606.612936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>resnet</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.156679</td>\n",
       "      <td>93</td>\n",
       "      <td>10555136</td>\n",
       "      <td>8547.191034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0.0020</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>resnet</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.157262</td>\n",
       "      <td>95</td>\n",
       "      <td>5294336</td>\n",
       "      <td>4868.378374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>2</td>\n",
       "      <td>768</td>\n",
       "      <td>resnet</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.157600</td>\n",
       "      <td>90</td>\n",
       "      <td>7596544</td>\n",
       "      <td>3258.366287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     learning_rate  batch_size  hidden_dim  n_layers  embedding_dim  \\\n",
       "290         0.0005          16         256         3           1024   \n",
       "422         0.0010          32         512         1           1024   \n",
       "300         0.0010          16         256         3           1024   \n",
       "379         0.0020          16         256         1           1024   \n",
       "229         0.0005          32         256         2            768   \n",
       "\n",
       "    encoder_type aggregator_type  best_val_loss  best_epoch  trainable_params  \\\n",
       "290       resnet          concat       0.154958          85          10555136   \n",
       "422       resnet          concat       0.155305          83          16484864   \n",
       "300       resnet          concat       0.156679          93          10555136   \n",
       "379       resnet          concat       0.157262          95           5294336   \n",
       "229       resnet          concat       0.157600          90           7596544   \n",
       "\n",
       "     total_training_time  \n",
       "290          7962.247344  \n",
       "422          2606.612936  \n",
       "300          8547.191034  \n",
       "379          4868.378374  \n",
       "229          3258.366287  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf = get_top_performers(df, n_top=5)[varying_attrs]\n",
    "# for each columns, rename the column by splitting the column name by \".\" and taking the last element\n",
    "subdf.columns = subdf.columns.str.split(\".\").str[-1]\n",
    "print(f\"Total training time: {(subdf['total_training_time'].sum() / 3600):.2f} hours\")\n",
    "print(f\"Average trainable params: {subdf['trainable_params'].mean() / 1000000:.1f}M\")\n",
    "subdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.642546\n"
     ]
    }
   ],
   "source": [
    "a = 0.65317\n",
    "b = 0.62066\n",
    "c = 0.64136\n",
    "d = 0.6565\n",
    "e = 0.64104\n",
    "\n",
    "\n",
    "total = a + b + c + d + e\n",
    "print(total / 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test/Y_KIBA_ci': 0.84797,\n",
       " 'test/Y_KIBA_mse': 0.195592,\n",
       " 'test/Y_KIBA_pearson': 0.841234,\n",
       " 'test/Y_KIBA_r2': 0.707488,\n",
       " 'test/Y_KIBA_rmse': 0.442218}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble = \"\"\"\n",
    "Name\n",
    "5 visualized\n",
    "test/Y_KIBA_ci\n",
    "test/Y_KIBA_mse\n",
    "test/Y_KIBA_pearson\n",
    "test/Y_KIBA_r2\n",
    "test/Y_KIBA_rmse\n",
    "•\n",
    "multi_modal_finetune_KIBA_rand_ensemble\n",
    "0.85238\n",
    "0.18802\n",
    "0.84787\n",
    "0.71881\n",
    "0.43361\n",
    "•\n",
    "multi_modal_finetune_KIBA_rand_ensemble\n",
    "0.84646\n",
    "0.19966\n",
    "0.83758\n",
    "0.70141\n",
    "0.44683\n",
    "•\n",
    "multi_modal_finetune_KIBA_rand_ensemble\n",
    "0.84461\n",
    "0.20252\n",
    "0.83521\n",
    "0.69713\n",
    "0.45002\n",
    "•\n",
    "multi_modal_finetune_KIBA_rand_ensemble\n",
    "0.84727\n",
    "0.19507\n",
    "0.84162\n",
    "0.70826\n",
    "0.44167\n",
    "•\n",
    "multi_modal_finetune_KIBA_rand_ensemble\n",
    "0.84913\n",
    "0.19269\n",
    "0.84389\n",
    "0.71183\n",
    "0.43896\n",
    "\"\"\"\n",
    "from statistics import mean\n",
    "lines = [line.strip() for line in ensemble.strip().split('\\n') if line.strip()]\n",
    "first_bullet = next(i for i, line in enumerate(lines) if line == '•')\n",
    "start_idx = 2\n",
    "column_names = lines[start_idx:first_bullet]\n",
    "data = {col: [] for col in column_names}\n",
    "\n",
    "i = first_bullet + 1\n",
    "while i < len(lines):\n",
    "    line = lines[i]\n",
    "    if line == '•' or line.startswith('multi_modal_'):\n",
    "        i += 1\n",
    "        continue\n",
    "    for j, col_name in enumerate(column_names):\n",
    "        if i + j < len(lines):\n",
    "            try:\n",
    "                value = float(lines[i + j])\n",
    "                data[col_name].append(value)\n",
    "            except ValueError:\n",
    "                break\n",
    "    \n",
    "    i += len(column_names)\n",
    "\n",
    "results = {}\n",
    "for col_name, values in data.items():\n",
    "    results[col_name] = mean(values)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test/Y_KIBA_ci': [0.85238, 0.84646, 0.84461, 0.84727, 0.84913],\n",
       " 'test/Y_KIBA_mse': [0.18802, 0.19966, 0.20252, 0.19507, 0.19269],\n",
       " 'test/Y_KIBA_pearson': [0.84787, 0.83758, 0.83521, 0.84162, 0.84389],\n",
       " 'test/Y_KIBA_r2': [0.71881, 0.70141, 0.69713, 0.70826, 0.71183],\n",
       " 'test/Y_KIBA_rmse': [0.43361, 0.44683, 0.45002, 0.44167, 0.43896]}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mb-vae-dti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
