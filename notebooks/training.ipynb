{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Experiments were conducted using:\n",
    "- `mb_vae_dti/training/run.py`: command line interface for training\n",
    "- and the scripts in `scripts/training/` for running the experiments\n",
    "\n",
    "This notebook shows some plots and analysis of the unsupervised pretraining, general DTI training and benchmark fine-tuning results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting working directory to: /home/robsyc/Desktop/thesis/MB-VAE-DTI\n"
     ]
    }
   ],
   "source": [
    "from resolve import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-30 11:43:35,308 - mb_vae_dti.validating.analysis - INFO - Loading 64 result files from notebooks/results/baseline_davis_rand\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/loss             0.2352\n",
      "test/Y_pKd_ci         0.8896\n",
      "test/Y_pKd_mse        0.2352\n",
      "test/Y_pKd_pearson    0.8324\n",
      "test/Y_pKd_r2         0.6924\n",
      "test/Y_pKd_rmse       0.4849\n",
      "dtype: float64\n",
      "Params: 13.9M\n"
     ]
    }
   ],
   "source": [
    "from mb_vae_dti.validating.analysis import *\n",
    "\n",
    "df = load_gridsearch_results(\"notebooks/results/baseline_davis_rand/\")\n",
    "\n",
    "top_5 = df.sort_values(by=\"best_val_loss\", ascending=True).head(5)\n",
    "print(round(get_test_averages(top_5), 4))\n",
    "print(f\"Params: {top_5['trainable_params'].mean() / 1000000:.1f}M\")\n",
    "\n",
    "# # get subsets with desired distinction (encoder_type and aggregator_type)\n",
    "# with_resnet = df[df[\"config.model.encoder_type\"] == \"resnet\"]\n",
    "# with_transformer = df[df[\"config.model.encoder_type\"] == \"transformer\"]\n",
    "\n",
    "# # get 5 best performers\n",
    "# with_resnet_best = with_resnet.sort_values(by=\"best_val_loss\", ascending=True).head(5)\n",
    "# with_transformer_best = with_transformer.sort_values(by=\"best_val_loss\", ascending=True).head(5)\n",
    "\n",
    "# # get stats\n",
    "# print(f\"Params: {with_resnet_best['trainable_params'].mean() / 1000000:.1f}M\")\n",
    "# print(get_test_averages(with_resnet_best))\n",
    "# print(\"-\" * 100)\n",
    "# print(f\"Params: {with_transformer_best['trainable_params'].mean() / 1000000:.1f}M\")\n",
    "# print(get_test_averages(with_transformer_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>best_val_loss</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>trainable_params</th>\n",
       "      <th>val/loss</th>\n",
       "      <th>val/Y_KIBA_ci</th>\n",
       "      <th>val/Y_KIBA_mse</th>\n",
       "      <th>val/Y_KIBA_pearson</th>\n",
       "      <th>val/Y_KIBA_r2</th>\n",
       "      <th>val/Y_KIBA_rmse</th>\n",
       "      <th>...</th>\n",
       "      <th>config.loss.weights</th>\n",
       "      <th>config.data.batch_size</th>\n",
       "      <th>config.data.h5_path</th>\n",
       "      <th>config.data.drug_features</th>\n",
       "      <th>config.data.target_features</th>\n",
       "      <th>config.model.embedding_dim</th>\n",
       "      <th>config.model.hidden_dim</th>\n",
       "      <th>config.model.n_layers</th>\n",
       "      <th>config.model.dropout</th>\n",
       "      <th>config.model.encoder_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>baseline_finetune_KIBA_cold_b00c0004</td>\n",
       "      <td>0.333460</td>\n",
       "      <td>50</td>\n",
       "      <td>16841728</td>\n",
       "      <td>0.333460</td>\n",
       "      <td>0.760062</td>\n",
       "      <td>0.333460</td>\n",
       "      <td>0.699008</td>\n",
       "      <td>0.472883</td>\n",
       "      <td>0.688165</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>64</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>resnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>baseline_finetune_KIBA_cold_b01c0004</td>\n",
       "      <td>0.338392</td>\n",
       "      <td>34</td>\n",
       "      <td>16841728</td>\n",
       "      <td>0.338392</td>\n",
       "      <td>0.753427</td>\n",
       "      <td>0.338392</td>\n",
       "      <td>0.690234</td>\n",
       "      <td>0.464987</td>\n",
       "      <td>0.670500</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>32</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>resnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>baseline_finetune_KIBA_cold_b00c0001</td>\n",
       "      <td>0.339152</td>\n",
       "      <td>26</td>\n",
       "      <td>12908544</td>\n",
       "      <td>0.339152</td>\n",
       "      <td>0.752964</td>\n",
       "      <td>0.339152</td>\n",
       "      <td>0.690663</td>\n",
       "      <td>0.463886</td>\n",
       "      <td>0.752744</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>64</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>768</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>baseline_finetune_KIBA_cold_b00c0018</td>\n",
       "      <td>0.339814</td>\n",
       "      <td>45</td>\n",
       "      <td>17375488</td>\n",
       "      <td>0.339814</td>\n",
       "      <td>0.753953</td>\n",
       "      <td>0.339814</td>\n",
       "      <td>0.691998</td>\n",
       "      <td>0.462838</td>\n",
       "      <td>0.690825</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>64</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>768</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>baseline_finetune_KIBA_cold_b00c0026</td>\n",
       "      <td>0.340133</td>\n",
       "      <td>26</td>\n",
       "      <td>12908544</td>\n",
       "      <td>0.340133</td>\n",
       "      <td>0.752621</td>\n",
       "      <td>0.340133</td>\n",
       "      <td>0.692200</td>\n",
       "      <td>0.462234</td>\n",
       "      <td>0.697769</td>\n",
       "      <td>...</td>\n",
       "      <td>1_0_0_0</td>\n",
       "      <td>32</td>\n",
       "      <td>data/input/dti.h5torch</td>\n",
       "      <td>FP-Morgan</td>\n",
       "      <td>FP-ESP</td>\n",
       "      <td>768</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         experiment_name  best_val_loss  best_epoch  \\\n",
       "61  baseline_finetune_KIBA_cold_b00c0004       0.333460          50   \n",
       "28  baseline_finetune_KIBA_cold_b01c0004       0.338392          34   \n",
       "16  baseline_finetune_KIBA_cold_b00c0001       0.339152          26   \n",
       "29  baseline_finetune_KIBA_cold_b00c0018       0.339814          45   \n",
       "33  baseline_finetune_KIBA_cold_b00c0026       0.340133          26   \n",
       "\n",
       "    trainable_params  val/loss  val/Y_KIBA_ci  val/Y_KIBA_mse  \\\n",
       "61          16841728  0.333460       0.760062        0.333460   \n",
       "28          16841728  0.338392       0.753427        0.338392   \n",
       "16          12908544  0.339152       0.752964        0.339152   \n",
       "29          17375488  0.339814       0.753953        0.339814   \n",
       "33          12908544  0.340133       0.752621        0.340133   \n",
       "\n",
       "    val/Y_KIBA_pearson  val/Y_KIBA_r2  val/Y_KIBA_rmse  ...  \\\n",
       "61            0.699008       0.472883         0.688165  ...   \n",
       "28            0.690234       0.464987         0.670500  ...   \n",
       "16            0.690663       0.463886         0.752744  ...   \n",
       "29            0.691998       0.462838         0.690825  ...   \n",
       "33            0.692200       0.462234         0.697769  ...   \n",
       "\n",
       "    config.loss.weights  config.data.batch_size     config.data.h5_path  \\\n",
       "61              1_0_0_0                      64  data/input/dti.h5torch   \n",
       "28              1_0_0_0                      32  data/input/dti.h5torch   \n",
       "16              1_0_0_0                      64  data/input/dti.h5torch   \n",
       "29              1_0_0_0                      64  data/input/dti.h5torch   \n",
       "33              1_0_0_0                      32  data/input/dti.h5torch   \n",
       "\n",
       "    config.data.drug_features  config.data.target_features  \\\n",
       "61                  FP-Morgan                       FP-ESP   \n",
       "28                  FP-Morgan                       FP-ESP   \n",
       "16                  FP-Morgan                       FP-ESP   \n",
       "29                  FP-Morgan                       FP-ESP   \n",
       "33                  FP-Morgan                       FP-ESP   \n",
       "\n",
       "    config.model.embedding_dim  config.model.hidden_dim  \\\n",
       "61                        1024                      512   \n",
       "28                        1024                      512   \n",
       "16                         768                      512   \n",
       "29                         768                      512   \n",
       "33                         768                      512   \n",
       "\n",
       "    config.model.n_layers  config.model.dropout  config.model.encoder_type  \n",
       "61                      3                   0.1                     resnet  \n",
       "28                      3                   0.1                     resnet  \n",
       "16                      2                   0.1                transformer  \n",
       "29                      3                   0.1                transformer  \n",
       "33                      2                   0.1                transformer  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mb-vae-dti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
